{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ed94b9e45574e7ebca224017982b160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2107f762b3834ae19a5186e391d756fd",
              "IPY_MODEL_215542cd266341d6965b108d9e614bac"
            ],
            "layout": "IPY_MODEL_8f2986b5cd2a4e589df8d629061ce145"
          }
        },
        "2107f762b3834ae19a5186e391d756fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88fa9a471afc4b6dad2c7f91df4e77cf",
            "placeholder": "​",
            "style": "IPY_MODEL_f747e21eccc3491a93de097510e1e65b",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "215542cd266341d6965b108d9e614bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c726d36ffb5b4d7fbe87dff23164056a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eadf73fea5ef474e9d9ca582fa2d6b96",
            "value": 1
          }
        },
        "8f2986b5cd2a4e589df8d629061ce145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88fa9a471afc4b6dad2c7f91df4e77cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f747e21eccc3491a93de097510e1e65b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c726d36ffb5b4d7fbe87dff23164056a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eadf73fea5ef474e9d9ca582fa2d6b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd8dd0195df24337bc7901ca74175507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_acb2d86572fe430aa648c844641f90d0",
              "IPY_MODEL_4907b2fb7ae44728a7bcd0a7042a5738",
              "IPY_MODEL_2510e5d667174a67bf0b93766eaa75f5"
            ],
            "layout": "IPY_MODEL_d230936a23df4735b2ef714a6a185d0d"
          }
        },
        "acb2d86572fe430aa648c844641f90d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6f68e15e20d47e2a10d173fde9fe943",
            "placeholder": "​",
            "style": "IPY_MODEL_c92129b430fa490aad143828abd01776",
            "value": "Tokenizing train set (num_proc=4): 100%"
          }
        },
        "4907b2fb7ae44728a7bcd0a7042a5738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02be3322d78a4943bd034af8fd1f46d0",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b7af6b8ecb14416a1b83dfed8c4b763",
            "value": 1000
          }
        },
        "2510e5d667174a67bf0b93766eaa75f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99817e8a8db245dfb35b61e8010242a1",
            "placeholder": "​",
            "style": "IPY_MODEL_27d42958b5f44dd5bb386f3b0c19835f",
            "value": " 1000/1000 [00:01&lt;00:00, 907.54 examples/s]"
          }
        },
        "d230936a23df4735b2ef714a6a185d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6f68e15e20d47e2a10d173fde9fe943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c92129b430fa490aad143828abd01776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02be3322d78a4943bd034af8fd1f46d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b7af6b8ecb14416a1b83dfed8c4b763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99817e8a8db245dfb35b61e8010242a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27d42958b5f44dd5bb386f3b0c19835f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2bcb885a72d4b8b8ea90b5f1144da52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0402c1afe7a2446e81f6c51aff81f995",
              "IPY_MODEL_522137992ce84613a3804d8878c91111",
              "IPY_MODEL_92469b57a7bc43b4893717c2b6d5c0ca"
            ],
            "layout": "IPY_MODEL_7b04324f857d45e585f9efb81af1db7c"
          }
        },
        "0402c1afe7a2446e81f6c51aff81f995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_758aadcb92254f55bc6f0df294a94595",
            "placeholder": "​",
            "style": "IPY_MODEL_21d95ce755e34890916f87836d5e6eaf",
            "value": "Tokenizing validation set (num_proc=4): 100%"
          }
        },
        "522137992ce84613a3804d8878c91111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15049c4ca78b4c20af32d79f55f58405",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_624024b6cf154446a4442d506c39d627",
            "value": 1000
          }
        },
        "92469b57a7bc43b4893717c2b6d5c0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b81dd732b5574fad98d46a21763b4ea9",
            "placeholder": "​",
            "style": "IPY_MODEL_075f48b830264b12bfab8be4911635cf",
            "value": " 1000/1000 [00:01&lt;00:00, 1297.63 examples/s]"
          }
        },
        "7b04324f857d45e585f9efb81af1db7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758aadcb92254f55bc6f0df294a94595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21d95ce755e34890916f87836d5e6eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15049c4ca78b4c20af32d79f55f58405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624024b6cf154446a4442d506c39d627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b81dd732b5574fad98d46a21763b4ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "075f48b830264b12bfab8be4911635cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd920bcfb590461787227f5c3451525f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd10842ad9a64ffb988b5e2304e7af2f",
              "IPY_MODEL_c04d935ac0bb4255a6e513ca319620bc",
              "IPY_MODEL_47f2b353eee24414b28070c57a36541d"
            ],
            "layout": "IPY_MODEL_36175dd818c5475c877ce4fcf6a75078"
          }
        },
        "fd10842ad9a64ffb988b5e2304e7af2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f164ef958b084d25acf9c1ad852bcb31",
            "placeholder": "​",
            "style": "IPY_MODEL_eba9c5a353084b13bdf45f00967800b9",
            "value": "Tokenizing test set (num_proc=4): 100%"
          }
        },
        "c04d935ac0bb4255a6e513ca319620bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3171d68c40694cb2b5ec2efc45f32536",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ec14253bc6d40b3906e2ee0d4685ec5",
            "value": 1000
          }
        },
        "47f2b353eee24414b28070c57a36541d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_001d70cd5ff447c3ba34e26f0a90b672",
            "placeholder": "​",
            "style": "IPY_MODEL_784a37e9865c4acba1f32aec242ce4ff",
            "value": " 1000/1000 [00:01&lt;00:00, 793.64 examples/s]"
          }
        },
        "36175dd818c5475c877ce4fcf6a75078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f164ef958b084d25acf9c1ad852bcb31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eba9c5a353084b13bdf45f00967800b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3171d68c40694cb2b5ec2efc45f32536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ec14253bc6d40b3906e2ee0d4685ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "001d70cd5ff447c3ba34e26f0a90b672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "784a37e9865c4acba1f32aec242ce4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4c52322092b4de5a3c8ca59c4aed696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_890e4488222f4a049aa6b3a993a83c4f",
              "IPY_MODEL_f3381036e4b240609055bce25e492354",
              "IPY_MODEL_a0b492f70be9414690ea0d4f4203d701"
            ],
            "layout": "IPY_MODEL_5466e5162bf24028970e801c861a7c34"
          }
        },
        "890e4488222f4a049aa6b3a993a83c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c1771a68d6d457195f358739cc69826",
            "placeholder": "​",
            "style": "IPY_MODEL_6dd5978f95844c15a33b901c57dcfb12",
            "value": "training_args.bin: 100%"
          }
        },
        "f3381036e4b240609055bce25e492354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c703236c8aa14bd4afa07898020efa67",
            "max": 5304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c197206d4334717bfd5da0872636173",
            "value": 5304
          }
        },
        "a0b492f70be9414690ea0d4f4203d701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f025a0a98ed543bbb9acf36a4254073c",
            "placeholder": "​",
            "style": "IPY_MODEL_c1c23cc3be1048a490eca2300d6ea475",
            "value": " 5.30k/5.30k [00:00&lt;00:00, 16.4kB/s]"
          }
        },
        "5466e5162bf24028970e801c861a7c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c1771a68d6d457195f358739cc69826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dd5978f95844c15a33b901c57dcfb12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c703236c8aa14bd4afa07898020efa67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c197206d4334717bfd5da0872636173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f025a0a98ed543bbb9acf36a4254073c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c23cc3be1048a490eca2300d6ea475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bbe5ff555684b4a8ac01333d3a8847e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7712e13e637a49dba92a4cb37556d664",
              "IPY_MODEL_512acf5d67ba4394b6b5f0bd2d6759e1",
              "IPY_MODEL_baf443f1024d4cb880b374cc6636c124"
            ],
            "layout": "IPY_MODEL_9e9d9b2616194a70910189c7a0cd1099"
          }
        },
        "7712e13e637a49dba92a4cb37556d664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bab4512815644deb070e008f2f2b4a3",
            "placeholder": "​",
            "style": "IPY_MODEL_59e7f4bb34b14669b8a8c9f663b0b352",
            "value": "Upload 2 LFS files: 100%"
          }
        },
        "512acf5d67ba4394b6b5f0bd2d6759e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce1204e7718f47bb8e44f611fa179f29",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_826c7237515c4954a273c5d5e08bad8b",
            "value": 2
          }
        },
        "baf443f1024d4cb880b374cc6636c124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808e44af5e8d40239dab6ff4427b570d",
            "placeholder": "​",
            "style": "IPY_MODEL_e9c780d21a724869b67794579b389bc0",
            "value": " 2/2 [00:28&lt;00:00, 28.03s/it]"
          }
        },
        "9e9d9b2616194a70910189c7a0cd1099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bab4512815644deb070e008f2f2b4a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59e7f4bb34b14669b8a8c9f663b0b352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce1204e7718f47bb8e44f611fa179f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "826c7237515c4954a273c5d5e08bad8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "808e44af5e8d40239dab6ff4427b570d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9c780d21a724869b67794579b389bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58f0ccefa8564b949e8b256a7291d64e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5300ad3406674ac39837e2144a0ff50f",
              "IPY_MODEL_445a01957cd64a24833c7899fcdff506",
              "IPY_MODEL_b52a58a93aa8497f8720cc5865f265db"
            ],
            "layout": "IPY_MODEL_aedced192db64b909e5998b7171b70b4"
          }
        },
        "5300ad3406674ac39837e2144a0ff50f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49144f22d3bb4db29dd076a19a278394",
            "placeholder": "​",
            "style": "IPY_MODEL_840d2f77382d4e18baff50780084bd05",
            "value": "model.safetensors: 100%"
          }
        },
        "445a01957cd64a24833c7899fcdff506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d55ec2aa46394d85bb7bb6f16ee5bf0a",
            "max": 669455360,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf633764cd6746949e610eeebccdfd41",
            "value": 669455360
          }
        },
        "b52a58a93aa8497f8720cc5865f265db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5842924f3ae4910bb5b725dee913dd6",
            "placeholder": "​",
            "style": "IPY_MODEL_9018d8d77d0e45fdac3d0cb704dcd955",
            "value": " 669M/669M [00:27&lt;00:00, 22.0MB/s]"
          }
        },
        "aedced192db64b909e5998b7171b70b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49144f22d3bb4db29dd076a19a278394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "840d2f77382d4e18baff50780084bd05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d55ec2aa46394d85bb7bb6f16ee5bf0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf633764cd6746949e610eeebccdfd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5842924f3ae4910bb5b725dee913dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9018d8d77d0e45fdac3d0cb704dcd955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c296057c9b0b4d8793dcf3814f31774c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c118c2389644be1b8d71d38b3fd9486",
              "IPY_MODEL_abf305588c734b57ba9de99b679ef5bf",
              "IPY_MODEL_d03a3c42d0e945be8e93889712aed2cb"
            ],
            "layout": "IPY_MODEL_c4cff48318954e6e8bdeb0b488ba3843"
          }
        },
        "6c118c2389644be1b8d71d38b3fd9486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d6c502174f94e869d4d98614aed3627",
            "placeholder": "​",
            "style": "IPY_MODEL_206530d7fa144410b945571fb0cf18b8",
            "value": "Tokenizing train set (num_proc=4): 100%"
          }
        },
        "abf305588c734b57ba9de99b679ef5bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1939141bb3eb4467a27d5604b305eb3f",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_023492ec7e524aab84ff3a047e048c7c",
            "value": 1000
          }
        },
        "d03a3c42d0e945be8e93889712aed2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4155944373945a388c47e27e29210ba",
            "placeholder": "​",
            "style": "IPY_MODEL_128ac639c0dd47e6b525a8771ee29620",
            "value": " 1000/1000 [00:01&lt;00:00, 1045.92 examples/s]"
          }
        },
        "c4cff48318954e6e8bdeb0b488ba3843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d6c502174f94e869d4d98614aed3627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "206530d7fa144410b945571fb0cf18b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1939141bb3eb4467a27d5604b305eb3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "023492ec7e524aab84ff3a047e048c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4155944373945a388c47e27e29210ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "128ac639c0dd47e6b525a8771ee29620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a1d4bfb04ad4134bd9064f3b8f80ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_284a0ae2655e48138b501482fa2ceea0",
              "IPY_MODEL_598a4e11da4745349d049ac576784366",
              "IPY_MODEL_2473c99a80ed480986d2e3c1cbf7f3c4"
            ],
            "layout": "IPY_MODEL_cd002dc153ba4cc999197a12eab99638"
          }
        },
        "284a0ae2655e48138b501482fa2ceea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b54b5e13e24e4d6e8e5723b70c13f296",
            "placeholder": "​",
            "style": "IPY_MODEL_f2911d49431245ecb73824f1f828233b",
            "value": "Tokenizing validation set (num_proc=4): 100%"
          }
        },
        "598a4e11da4745349d049ac576784366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9adc1192538480a9b6c053bdb5f0dbd",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39bd9830f06e4c97ad41e62cf2bc48e4",
            "value": 1000
          }
        },
        "2473c99a80ed480986d2e3c1cbf7f3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02e3cf1a3d7149eaa5a7e8326103a9d9",
            "placeholder": "​",
            "style": "IPY_MODEL_3c3ffead59374fa69671023ce4f247b3",
            "value": " 1000/1000 [00:01&lt;00:00, 775.07 examples/s]"
          }
        },
        "cd002dc153ba4cc999197a12eab99638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b54b5e13e24e4d6e8e5723b70c13f296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2911d49431245ecb73824f1f828233b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9adc1192538480a9b6c053bdb5f0dbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39bd9830f06e4c97ad41e62cf2bc48e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02e3cf1a3d7149eaa5a7e8326103a9d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3ffead59374fa69671023ce4f247b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71b5f88b9efa49f782bd03801f81b083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c46d7268e6448b8a84c705fba972322",
              "IPY_MODEL_e33a3162627b49b9b9df49401db15662",
              "IPY_MODEL_cb444ef48f3e4980b7ce2e0d243c2216"
            ],
            "layout": "IPY_MODEL_03e73a9b8a4b4c7db1c814efd5bc9d6d"
          }
        },
        "5c46d7268e6448b8a84c705fba972322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8fe6511225c4077b48092d92a55c43d",
            "placeholder": "​",
            "style": "IPY_MODEL_220804f0ce294807a32e6899fa7ef325",
            "value": "Tokenizing test set (num_proc=4): 100%"
          }
        },
        "e33a3162627b49b9b9df49401db15662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_835f8010a49c4f13bba2a58bc0c970ec",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57989d7da060423f91b2a8498b90d1a0",
            "value": 1000
          }
        },
        "cb444ef48f3e4980b7ce2e0d243c2216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_218f7b8e3c1943f2ba7adee2e7a99c84",
            "placeholder": "​",
            "style": "IPY_MODEL_be30dfd2d581439f80d3effdc1281bfe",
            "value": " 1000/1000 [00:01&lt;00:00, 1063.37 examples/s]"
          }
        },
        "03e73a9b8a4b4c7db1c814efd5bc9d6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8fe6511225c4077b48092d92a55c43d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "220804f0ce294807a32e6899fa7ef325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "835f8010a49c4f13bba2a58bc0c970ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57989d7da060423f91b2a8498b90d1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "218f7b8e3c1943f2ba7adee2e7a99c84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be30dfd2d581439f80d3effdc1281bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d3ec6ea6f6a445ab5a3dc0ff0f467e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_578c0bb0f6d34b47b4ec459ac6ca07b2",
              "IPY_MODEL_f070f768b4d64855a3420cf7933d3a6c"
            ],
            "layout": "IPY_MODEL_a8d04b87ecaf4034a7fdb0625e038331"
          }
        },
        "578c0bb0f6d34b47b4ec459ac6ca07b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e18c513402b9417ebeb52a3e970ef672",
            "placeholder": "​",
            "style": "IPY_MODEL_40bd9e818807482a97200779e4761c6b",
            "value": "0.023 MB of 0.023 MB uploaded\r"
          }
        },
        "f070f768b4d64855a3420cf7933d3a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b135de22c608472d9b4be4563e10651c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77bfa1f6a91c4a50a645f4d704a51a79",
            "value": 1
          }
        },
        "a8d04b87ecaf4034a7fdb0625e038331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e18c513402b9417ebeb52a3e970ef672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40bd9e818807482a97200779e4761c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b135de22c608472d9b4be4563e10651c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77bfa1f6a91c4a50a645f4d704a51a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsl5710/greenland/blob/main/GREENLAND_Fine_tuning_mostupdated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup & Installation"
      ],
      "metadata": {
        "id": "W3Bum5rWN9oL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and upgrade necessary libraries\n",
        "# !pip install --quiet --upgrade pip\n",
        "# !pip install --quiet --upgrade transformers\n",
        "# !pip install --quiet --upgrade datasets\n",
        "# !pip install --quiet --upgrade wandb\n",
        "# !pip install --quiet git+https://github.com/huggingface/peft.git peft\n",
        "\n",
        "\n",
        "# First uninstall existing packages to avoid conflicts\n",
        "# !pip uninstall -y transformers adapters adapter-transformers\n",
        "\n",
        "# Now install in the correct order with specific versions\n",
        "!pip install --quiet transformers==4.46.2\n",
        "!pip install --quiet adapter-transformers\n",
        "!pip install --quiet adapters\n",
        "!pip install --quiet datasets\n",
        "!pip install --quiet wandb\n",
        "!pip install --quiet git+https://github.com/huggingface/peft.git\n",
        "!pip install colorlog\n",
        "# Verify installations\n",
        "print(\"Installed versions:\")\n",
        "!pip show transformers | grep Version\n",
        "!pip show adapter-transformers | grep Version\n"
      ],
      "metadata": {
        "id": "EnCpombcOC4Z",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a41295-13e4-43ac-e2ba-e9e7d2db7d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "adapters 1.0.1 requires transformers~=4.45.2, but you have transformers 4.46.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (6.9.0)\n",
            "Installed versions:\n",
            "Version: 4.45.2\n",
            "Version: 4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Import Libraries"
      ],
      "metadata": {
        "id": "52iDZjrEyY3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import torch\n",
        "# import wandb\n",
        "# import pandas as pd\n",
        "# from typing import Dict, Optional\n",
        "# from torch.utils.data import DataLoader\n",
        "# from transformers import (\n",
        "#     AutoTokenizer,\n",
        "#     AutoModelForSequenceClassification,\n",
        "#     Trainer,\n",
        "#     TrainingArguments,\n",
        "#     DataCollatorWithPadding,\n",
        "# )\n",
        "\n",
        "# from peft import (\n",
        "#     LoraConfig,\n",
        "#     PrefixTuningConfig,\n",
        "#     PromptTuningConfig,\n",
        "#     AdaLoraConfig,\n",
        "#     IA3Config,\n",
        "#     get_peft_model,\n",
        "#     PeftModel,\n",
        "#     TaskType,\n",
        "#     PeftConfig\n",
        "# )\n",
        "# from datasets import load_dataset, Dataset\n",
        "# from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "# from peft import get_peft_model, LoraConfig, TaskType, AutoPeftModelForSequenceClassification\n",
        "# from google.colab import drive\n",
        "# from requests.exceptions import HTTPError\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import wandb\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Optional, Union, Callable\n",
        "from dataclasses import dataclass\n",
        "from torch.utils.data import DataLoader\n",
        "from requests.exceptions import HTTPError\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "# Transformers imports\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainerCallback,\n",
        ")\n",
        "\n",
        "# Adapter imports\n",
        "from adapters import (\n",
        "    SeqBnConfig,              # Sequential bottleneck adapter\n",
        "    DoubleSeqBnConfig,        # Double sequential bottleneck\n",
        "    ParBnConfig,              # Parallel bottleneck\n",
        "    SeqBnInvConfig,           # Sequential invertible adapter\n",
        "    DoubleSeqBnInvConfig,     # Double sequential invertible\n",
        "    CompacterConfig,          # Compacter\n",
        "    CompacterPlusPlusConfig,  # Compacter++\n",
        "    PrefixTuningConfig,       # Prefix tuning\n",
        "    LoRAConfig,               # LoRA\n",
        "    IA3Config,                # IA³\n",
        "    MAMConfig,                # Mix-and-Match\n",
        "    UniPELTConfig,            # UniPELT\n",
        "    PromptTuningConfig,       # Prompt Tuning\n",
        "    LoReftConfig,             # ReFT\n",
        "    NoReftConfig,             # NoReFT\n",
        "    DiReftConfig,             # DiReFT\n",
        "    Stack,                    # For stacking adapters\n",
        "    Parallel,                 # For parallel adapters\n",
        "    Fuse,                     # For adapter fusion\n",
        "    AdapterConfig,            # Base adapter config\n",
        "    ConfigUnion,               # For combining configurations\n",
        "    AutoAdapterModel,\n",
        "    AdapterTrainer\n",
        ")\n",
        "\n",
        "# PEFT imports\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PrefixTuningConfig,\n",
        "    PromptTuningConfig,\n",
        "    AdaLoraConfig,\n",
        "    IA3Config,\n",
        "    get_peft_model,\n",
        "    PeftModel,\n",
        "    TaskType,\n",
        "    PeftConfig,\n",
        "    AutoPeftModelForSequenceClassification\n",
        ")\n",
        "\n",
        "# Dataset and metrics imports\n",
        "from datasets import (\n",
        "    load_dataset,\n",
        "    Dataset,\n",
        "    DatasetDict\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        "    classification_report,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "# Custom trainer components\n",
        "class GatingScoreCallback(TrainerCallback):\n",
        "    \"\"\"Callback for monitoring adapter gating scores\"\"\"\n",
        "    def on_step_end(self, args, state, control, model=None, **kwargs):\n",
        "        if hasattr(model, \"get_adapter_gating_scores\"):\n",
        "            scores = model.get_adapter_gating_scores()\n",
        "            if wandb.run:\n",
        "                wandb.log({\"gating_scores\": scores})\n",
        "\n",
        "class ModuleNotFoundHandler:\n",
        "    \"\"\"Handler for gracefully managing missing optional dependencies\"\"\"\n",
        "    @staticmethod\n",
        "    def check_optional_dependencies():\n",
        "        dependencies = {\n",
        "            \"wandb\": \"Weights & Biases for experiment tracking\",\n",
        "            \"adapter-transformers\": \"Adapter-based fine-tuning support\",\n",
        "            \"peft\": \"Parameter-Efficient Fine-Tuning support\"\n",
        "        }\n",
        "\n",
        "        missing = []\n",
        "        for module, description in dependencies.items():\n",
        "            try:\n",
        "                __import__(module)\n",
        "            except ImportError:\n",
        "                missing.append(f\"{module} ({description})\")\n",
        "\n",
        "        if missing:\n",
        "            print(\"Optional dependencies missing:\")\n",
        "            for m in missing:\n",
        "                print(f\"- {m}\")\n",
        "            print(\"\\nYou can install them with:\")\n",
        "            print(\"pip install \" + \" \".join([m.split()[0] for m in missing]))\n",
        "\n",
        "# Initialize dependency check\n",
        "ModuleNotFoundHandler.check_optional_dependencies()"
      ],
      "metadata": {
        "id": "X0pZE3KRbLLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e7b68a-2ba1-48b7-dacd-21d0dd9ded48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optional dependencies missing:\n",
            "- adapter-transformers (Adapter-based fine-tuning support)\n",
            "\n",
            "You can install them with:\n",
            "pip install adapter-transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Define Model Checkpoints"
      ],
      "metadata": {
        "id": "FbzH1OPlz13a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoints = {\n",
        "    \"MBERT_uncased\": {\n",
        "        \"path\": \"google-bert/bert-base-multilingual-uncased\",\n",
        "        \"max_length\": 512\n",
        "    },\n",
        "    # \"XLM_100\": {\n",
        "    #     \"path\": \"FacebookAI/xlm-mlm-100-1280\",\n",
        "    #     \"max_length\": 512\n",
        "    # },\n",
        "    # \"XLM_17\": {\n",
        "    #     \"path\": \"FacebookAI/xlm-mlm-17-1280\",\n",
        "    #     \"max_length\": 512\n",
        "    # },\n",
        "    # \"XLM-RoBERTa_xxl\": {\n",
        "    #     \"path\": \"facebook/xlm-roberta-xxl\",\n",
        "    #     \"max_length\": 512\n",
        "    # },\n",
        "    # \"mDeBERTa_v3_base\": {\n",
        "    #     \"path\": \"microsoft/mdeberta-v3-base\",\n",
        "    #     \"max_length\": 512\n",
        "    # },\n",
        "    # \"S-BERT_LaBSE\": {\n",
        "    #     \"path\": \"sentence-transformers/LaBSE\",\n",
        "    #     \"max_length\": 512\n",
        "    # },\n",
        "    # \"S-BERT_distiluse\": {\n",
        "    #     \"path\": \"sentence-transformers/distiluse-base-multilingual-cased\",\n",
        "    #     \"max_length\": 512\n",
        "    # },\n",
        "    # \"XLM-R_bernice\": {\n",
        "    #     \"path\": \"jhu-clsp/bernice\",\n",
        "    #     \"max_length\": 512\n",
        "    # },\n",
        "    # \"XLM-T_twitter\": {\n",
        "    #     \"path\": \"cardiffnlp/twitter-xlm-roberta-base\",\n",
        "    #     \"max_length\": 512\n",
        "    # },\n",
        "    # \"XLM-E_align\": {\n",
        "    #     \"path\": \"microsoft/xlm-align-base\",\n",
        "    #     \"max_length\": 512\n",
        "    # },\n",
        "    # \"XLM-E_infoxlm_large\": {\n",
        "    #     \"path\": \"microsoft/infoxlm-large\",\n",
        "    #     \"max_length\": 512\n",
        "    # },\n",
        "    # \"XLM-V_base\": {\n",
        "    #     \"path\": \"facebook/xlm-v-base\",\n",
        "    #     \"max_length\": 512\n",
        "    # }\n",
        "}\n",
        "\n",
        "\n",
        "# model_checkpoints = {\n",
        "#     \"MBERT_uncased\": \"google-bert/bert-base-multilingual-uncased\",\n",
        "#     # \"MBERT_cased\": \"google-bert/bert-base-multilingual-cased\",\n",
        "#     \"XLM_100\": \"FacebookAI/xlm-mlm-100-1280\",\n",
        "#     \"XLM_17\": \"FacebookAI/xlm-mlm-17-1280\",\n",
        "#     # \"XLM-RoBERTa_large\": \"FacebookAI/xlm-roberta-large\",\n",
        "#     # \"XLM-RoBERTa_base\": \"FacebookAI/xlm-roberta-base\",\n",
        "#     # \"XLM-RoBERTa_xl\": \"facebook/xlm-roberta-xl\",\n",
        "#     \"XLM-RoBERTa_xxl\": \"facebook/xlm-roberta-xxl\",\n",
        "#     \"mDeBERTa_v3_base\": \"microsoft/mdeberta-v3-base\",\n",
        "#     # \"M-distilBERT\": \"distilbert/distilbert-base-multilingual-cased\",\n",
        "#     \"S-BERT_LaBSE\": \"sentence-transformers/LaBSE\",\n",
        "#     \"S-BERT_distiluse\": \"sentence-transformers/distiluse-base-multilingual-cased\",\n",
        "#     \"XLM-R_bernice\": \"jhu-clsp/bernice\",\n",
        "#     \"XLM-T_twitter\": \"cardiffnlp/twitter-xlm-roberta-base\",\n",
        "#     \"XLM-E_align\": \"microsoft/xlm-align-base\",\n",
        "#     # \"XLM-E_infoxlm_base\": \"microsoft/infoxlm-base\",\n",
        "#     \"XLM-E_infoxlm_large\": \"microsoft/infoxlm-large\",\n",
        "#     \"XLM-V_base\": \"facebook/xlm-v-base\"\n",
        "# }\n",
        "\n",
        "# model_checkpoints = {\n",
        "    # \"MBERT_uncased\": \"google-bert/bert-base-multilingual-uncased\",\n",
        "    # \"XLM_100\": \"FacebookAI/xlm-mlm-100-1280\",\n",
        "    # \"XLM_17\": \"FacebookAI/xlm-mlm-17-1280\",\n",
        "    # \"XLM-RoBERTa_xxl\": \"facebook/xlm-roberta-xxl\",\n",
        "    # \"mDeBERTa_v3_base\": \"microsoft/mdeberta-v3-base\",\n",
        "    # \"S-BERT_LaBSE\": \"sentence-transformers/LaBSE\",\n",
        "    # \"S-BERT_distiluse\": \"sentence-transformers/distiluse-base-multilingual-cased\",\n",
        "    # \"XLM-R_bernice\": \"jhu-clsp/bernice\",\n",
        "    # \"XLM-T_twitter\": \"cardiffnlp/twitter-xlm-roberta-base\",\n",
        "    # \"XLM-E_align\": \"microsoft/xlm-align-base\",\n",
        "    #     \"XLM-E_infoxlm_large\": \"microsoft/infoxlm-large\",\n",
        "    # \"XLM-V_base\": \"facebook/xlm-v-base\"\n",
        "# }\n",
        "\n"
      ],
      "metadata": {
        "id": "DBdcWP1pz6CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Authenticate and Initialize"
      ],
      "metadata": {
        "id": "CciQJFQ3y5cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Authenticate with Hugging Face\n",
        "!huggingface-cli login --token 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\n",
        "\n",
        "# Authenticate with W&B\n",
        "def authenticate_wandb():\n",
        "    try:\n",
        "      wandb.login(key=\"1b5caf38a8b6ada0e6918798e9379b2ea764062d\")\n",
        "      wandb.init(project=\"greenland\")\n",
        "      print(\"Authentication successful!\")\n",
        "    except HTTPError as e:\n",
        "      print(f\"Authentication failed: {e}\")\n",
        "\n",
        "authenticate_wandb()\n"
      ],
      "metadata": {
        "id": "tYgicB7QzBcj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "91bc14e0-98e2-4fb5-a989-f1af9e7da21d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `greenland` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `greenland`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241129_072412-ezzrlheh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pike/greenland/runs/ezzrlheh' target=\"_blank\">fiery-eon-368</a></strong> to <a href='https://wandb.ai/pike/greenland' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/pike/greenland' target=\"_blank\">https://wandb.ai/pike/greenland</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/pike/greenland/runs/ezzrlheh' target=\"_blank\">https://wandb.ai/pike/greenland/runs/ezzrlheh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authentication successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Define Save Paths and Ensure Directories Exist"
      ],
      "metadata": {
        "id": "fmhXLfnvzME0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define save locations\n",
        "local_save_path = \"/content/sample_data/best_models/\"\n",
        "drive_save_path = \"/content/drive/MyDrive/GREENLAND/Modeling/Best_models/\"\n",
        "results_dir = \"/content/drive/MyDrive/GREENLAND/Results/\"\n",
        "\n",
        "# Ensure save directories exist\n",
        "os.makedirs(local_save_path, exist_ok=True)\n",
        "os.makedirs(drive_save_path, exist_ok=True)\n",
        "os.makedirs(results_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "fsuy1-W4zVCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Load and Process the Dataset"
      ],
      "metadata": {
        "id": "N_cUoRK-zXCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load datasets from CSV files in Google Drive\n",
        "# train_df = pd.read_csv('/content/drive/MyDrive/GREENLAND/Datasets/Consolidated_Data/Experiment_Training_Splits/train_data.csv')\n",
        "# val_df = pd.read_csv('/content/drive/MyDrive/GREENLAND/Datasets/Consolidated_Data/Experiment_Training_Splits/val_data.csv')\n",
        "# test_df = pd.read_csv('/content/drive/MyDrive/GREENLAND/Datasets/Consolidated_Data/Experiment_Training_Splits/test_data.csv')\n",
        "\n",
        "# # Convert to Hugging Face Dataset format\n",
        "# train_dataset = Dataset.from_pandas(train_df)\n",
        "# val_dataset = Dataset.from_pandas(val_df)\n",
        "# test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "\n",
        "# # Combine datasets into a dictionary for easy access\n",
        "# dataset = {\n",
        "#     \"train\": train_dataset,\n",
        "#     \"validation\": val_dataset,\n",
        "#     \"test\": test_dataset\n",
        "# }\n",
        "\n",
        "\n",
        "# # Load datasets from CSV files in Google Drive\n",
        "# train_df = pd.read_csv('/content/drive/MyDrive/GREENLAND/Datasets/Consolidated_Data/Experiment_Training_Splits/train_data.csv')\n",
        "# val_df = pd.read_csv('/content/drive/MyDrive/GREENLAND/Datasets/Consolidated_Data/Experiment_Training_Splits/val_data.csv')\n",
        "# test_df = pd.read_csv('/content/drive/MyDrive/GREENLAND/Datasets/Consolidated_Data/Experiment_Training_Splits/test_data.csv')\n",
        "\n",
        "# # Sample 1000 examples from each dataset with random seed for reproducibility\n",
        "# train_df_sampled = train_df.sample(n=1000, random_state=42)\n",
        "# val_df_sampled = val_df.sample(n=1000, random_state=42)\n",
        "# test_df_sampled = test_df.sample(n=1000, random_state=42)\n",
        "\n",
        "# # Convert to Hugging Face Dataset format\n",
        "# train_dataset = Dataset.from_pandas(train_df_sampled)\n",
        "# val_dataset = Dataset.from_pandas(val_df_sampled)\n",
        "# test_dataset = Dataset.from_pandas(test_df_sampled)\n",
        "\n",
        "# # Combine datasets into a dictionary for easy access\n",
        "# dataset = {\n",
        "#     \"train\": train_dataset,\n",
        "#     \"validation\": val_dataset,\n",
        "#     \"test\": test_dataset\n",
        "# }\n",
        "\n",
        "# print(\"Dataset sizes after sampling:\")\n",
        "# print(f\"Train: {len(train_dataset)}\")\n",
        "# print(f\"Validation: {len(val_dataset)}\")\n",
        "# print(f\"Test: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "YM4oJ57pzdri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Define Dataset Processing Functions"
      ],
      "metadata": {
        "id": "GuZkjbIp1AJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_dataset(dataset):\n",
        "    print(\"\\nDataset Verification:\")\n",
        "    for split in dataset.keys():\n",
        "        print(f\"\\n{split.capitalize()} set:\")\n",
        "        print(\"Number of examples:\", len(dataset[split]))\n",
        "        print(\"Features:\", dataset[split].features)\n",
        "        print(\"Sample labels:\", dataset[split][\"label\"][:5])\n",
        "        # Check data type differently\n",
        "        print(\"Label type:\", type(dataset[split][\"label\"]))\n",
        "        # Print first few label types to understand the structure\n",
        "        print(\"Sample label types:\", [type(label) for label in dataset[split][\"label\"][:5]])\n",
        "    return True\n",
        "\n",
        "def tokenize_datasets(model_name, dataset):\n",
        "    model_info = model_checkpoints[model_name]\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_info[\"path\"])\n",
        "    max_length = model_info[\"max_length\"]\n",
        "\n",
        "    print(f\"Using max_length={max_length} for model {model_name}\")\n",
        "\n",
        "    def preprocess_function(examples):\n",
        "        # Convert boolean labels to integers, handling list input\n",
        "        labels = [int(label) if isinstance(label, bool) else int(bool(label))\n",
        "                 for label in examples[\"label\"]]\n",
        "\n",
        "        # Tokenize the text\n",
        "        tokenized = tokenizer(\n",
        "            examples[\"text\"],\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=None\n",
        "        )\n",
        "\n",
        "        # Add converted labels to the tokenized output\n",
        "        tokenized[\"labels\"] = labels\n",
        "        return tokenized\n",
        "\n",
        "    # Print sample of data before tokenization\n",
        "    print(\"\\nBefore tokenization:\")\n",
        "    print(\"Sample of original labels:\", dataset[\"train\"][\"label\"][:5])\n",
        "    print(\"Original label type:\", type(dataset[\"train\"][\"label\"][0]))\n",
        "\n",
        "    tokenized_data = {\n",
        "        split: data.map(\n",
        "            preprocess_function,\n",
        "            batched=True,\n",
        "            batch_size=1000,\n",
        "            num_proc=4,\n",
        "            remove_columns=data.column_names,\n",
        "            desc=f\"Tokenizing {split} set\"\n",
        "        )\n",
        "        for split, data in dataset.items()\n",
        "    }\n",
        "\n",
        "    # Verify the processed labels\n",
        "    print(\"\\nAfter tokenization:\")\n",
        "    print(\"Sample of processed labels:\", tokenized_data[\"train\"][\"labels\"][:5])\n",
        "    print(\"Processed label type:\", type(tokenized_data[\"train\"][\"labels\"][0]))\n",
        "\n",
        "    return tokenized_data\n",
        "\n",
        "def analyze_text_lengths(dataset):\n",
        "    \"\"\"\n",
        "    Analyze text lengths in the dataset without tokenization first\n",
        "    \"\"\"\n",
        "    # Get raw text lengths\n",
        "    lengths = [len(text.split()) for text in dataset[\"train\"][\"text\"]]\n",
        "\n",
        "    stats = {\n",
        "        \"average_length\": sum(lengths)/len(lengths),\n",
        "        \"max_length\": max(lengths),\n",
        "        \"median_length\": sorted(lengths)[len(lengths)//2],\n",
        "        \"95th_percentile\": sorted(lengths)[int(len(lengths)*0.95)],\n",
        "        \"length_distribution\": {\n",
        "            \"< 128 words\": sum(1 for l in lengths if l < 128),\n",
        "            \"128-256 words\": sum(1 for l in lengths if 128 <= l < 256),\n",
        "            \"256-512 words\": sum(1 for l in lengths if 256 <= l < 512),\n",
        "            \"> 512 words\": sum(1 for l in lengths if l >= 512)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Calculate percentages for distribution\n",
        "    total_samples = len(lengths)\n",
        "    stats[\"length_distribution_percent\"] = {\n",
        "        k: (v/total_samples * 100) for k, v in stats[\"length_distribution\"].items()\n",
        "    }\n",
        "\n",
        "    print(\"\\nText Length Analysis (word-based):\")\n",
        "    print(f\"Average length: {stats['average_length']:.1f} words\")\n",
        "    print(f\"Median length: {stats['median_length']} words\")\n",
        "    print(f\"Max length: {stats['max_length']} words\")\n",
        "    print(f\"95th percentile: {stats['95th_percentile']} words\")\n",
        "    print(\"\\nLength Distribution:\")\n",
        "    for category, count in stats[\"length_distribution\"].items():\n",
        "        percentage = stats[\"length_distribution_percent\"][category]\n",
        "        print(f\"{category}: {count} texts ({percentage:.1f}%)\")\n",
        "\n",
        "    # Character-based analysis\n",
        "    char_lengths = [len(text) for text in dataset[\"train\"][\"text\"]]\n",
        "    stats[\"char_stats\"] = {\n",
        "        \"average_length\": sum(char_lengths)/len(char_lengths),\n",
        "        \"max_length\": max(char_lengths),\n",
        "        \"median_length\": sorted(char_lengths)[len(char_lengths)//2],\n",
        "        \"95th_percentile\": sorted(char_lengths)[int(len(char_lengths)*0.95)]\n",
        "    }\n",
        "\n",
        "    print(\"\\nCharacter-based Analysis:\")\n",
        "    print(f\"Average length: {stats['char_stats']['average_length']:.1f} characters\")\n",
        "    print(f\"Median length: {stats['char_stats']['median_length']} characters\")\n",
        "    print(f\"Max length: {stats['char_stats']['max_length']} characters\")\n",
        "    print(f\"95th percentile: {stats['char_stats']['95th_percentile']} characters\")\n",
        "\n",
        "    return stats\n",
        "\n"
      ],
      "metadata": {
        "id": "b9J4Pt8T1RKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Define Loss Functions"
      ],
      "metadata": {
        "id": "2vpUzaJHz-W2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightedFocalLoss(torch.nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2):\n",
        "        super(WeightedFocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        # Apply softmax for multi-class probabilities\n",
        "        probs = torch.softmax(logits, dim=1)[:, 1]  # Probability for positive class\n",
        "        labels = labels.float()\n",
        "        BCE_loss = torch.nn.functional.binary_cross_entropy(probs, labels, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
        "        return F_loss.mean()\n",
        "\n",
        "class SymmetricCrossEntropyLoss(torch.nn.Module):\n",
        "    def __init__(self, alpha=0.1, beta=1.0):\n",
        "        super(SymmetricCrossEntropyLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        ce_loss = torch.nn.functional.cross_entropy(logits, labels)\n",
        "        labels_one_hot = torch.nn.functional.one_hot(labels, num_classes=logits.size(-1))\n",
        "        rce_loss = -((torch.softmax(logits, dim=1) * labels_one_hot).sum(dim=-1).log().mean())\n",
        "        return self.alpha * ce_loss + self.beta * rce_loss\n",
        "\n",
        "\n",
        "class ModifiedBCEWithLogitsLoss(torch.nn.Module):\n",
        "    def forward(self, logits, labels):\n",
        "        # Ensure logits are the right shape (batch_size, num_classes)\n",
        "        if len(logits.shape) == 1:\n",
        "            logits = logits.unsqueeze(-1)\n",
        "        # Get the positive class logits\n",
        "        pos_logits = logits[:, 1]\n",
        "        return torch.nn.functional.binary_cross_entropy_with_logits(\n",
        "            pos_logits, labels.float(), reduction='mean'\n",
        "        )\n",
        "\n",
        "class ModifiedSquaredBCEWithLogitsLoss(torch.nn.Module):\n",
        "    def forward(self, logits, labels):\n",
        "        # Convert labels to float and ensure correct shape\n",
        "        labels = labels.float().view(-1)\n",
        "\n",
        "        # Ensure logits are the right shape for binary classification\n",
        "        if len(logits.shape) > 1 and logits.shape[1] == 2:\n",
        "            logits = logits[:, 1]  # Take the logit for positive class\n",
        "\n",
        "        # Apply sigmoid to get probabilities\n",
        "        probs = torch.sigmoid(logits)\n",
        "        return torch.mean((probs - labels) ** 2)\n",
        "\n",
        "class ModifiedWeightedBinaryCrossEntropy(torch.nn.Module):\n",
        "    def __init__(self, pos_weight):\n",
        "        super().__init__()\n",
        "        self.pos_weight = pos_weight\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        # Convert labels to float and ensure correct shape\n",
        "        labels = labels.float().view(-1)\n",
        "\n",
        "        # Ensure logits are the right shape for binary classification\n",
        "        if len(logits.shape) > 1 and logits.shape[1] == 2:\n",
        "            logits = logits[:, 1]  # Take the logit for positive class\n",
        "\n",
        "        return torch.nn.functional.binary_cross_entropy_with_logits(\n",
        "            logits, labels, pos_weight=self.pos_weight, reduction='mean'\n",
        "        )\n",
        "\n",
        "class ModifiedSupervisedContrastiveCrossEntropyLoss(torch.nn.Module):\n",
        "    def __init__(self, temperature=0.07, lam=0.5):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.lam = lam\n",
        "        self.ce_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        # Standard cross-entropy loss\n",
        "        ce_loss = self.ce_loss(logits, labels.long())\n",
        "\n",
        "        # Contrastive loss\n",
        "        normalized_logits = torch.nn.functional.normalize(logits, dim=1)\n",
        "        similarity_matrix = torch.matmul(normalized_logits, normalized_logits.t()) / self.temperature\n",
        "\n",
        "        # Create mask for positive pairs\n",
        "        labels = labels.view(-1, 1)\n",
        "        mask = (labels == labels.t()).float()\n",
        "\n",
        "        # Compute contrastive loss\n",
        "        exp_sim = torch.exp(similarity_matrix)\n",
        "        log_prob = similarity_matrix - torch.log(exp_sim.sum(dim=1, keepdim=True))\n",
        "\n",
        "        # Compute mean of positive pairs\n",
        "        mask_sum = mask.sum(dim=1)\n",
        "        mask_sum = torch.clamp(mask_sum, min=1e-8)  # Avoid division by zero\n",
        "        con_loss = (mask * log_prob).sum(dim=1) / mask_sum\n",
        "        con_loss = -con_loss.mean()\n",
        "\n",
        "        # Combine losses\n",
        "        return self.lam * ce_loss + (1 - self.lam) * con_loss\n",
        "\n",
        "class HuberLoss(torch.nn.Module):\n",
        "    def __init__(self, delta=1.0):\n",
        "        super(HuberLoss, self).__init__()\n",
        "        self.delta = delta\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        # Convert labels to float and ensure correct shape\n",
        "        labels = labels.float().view(-1)\n",
        "\n",
        "        # Ensure logits are the right shape for binary classification\n",
        "        if len(logits.shape) > 1 and logits.shape[1] == 2:\n",
        "            logits = logits[:, 1]  # Take the logit for the positive class\n",
        "\n",
        "        # Apply sigmoid to get probabilities\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        # Calculate Huber loss\n",
        "        diff = probs - labels\n",
        "        abs_diff = torch.abs(diff)\n",
        "        quadratic = torch.where(abs_diff <= self.delta, 0.5 * diff ** 2, self.delta * (abs_diff - 0.5 * self.delta))\n",
        "        return quadratic.mean()\n"
      ],
      "metadata": {
        "id": "Zo0XodDEd9MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Loss Functions Factory"
      ],
      "metadata": {
        "id": "zkDSx51heQMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_functions(device=None):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    return {\n",
        "        # \"CrossEntropyLoss\": torch.nn.CrossEntropyLoss().to(device),\n",
        "        # \"BCEWithLogitsLoss\": ModifiedBCEWithLogitsLoss().to(device),\n",
        "        # \"SquaredBCEWithLogitsLoss\": ModifiedSquaredBCEWithLogitsLoss().to(device),\n",
        "        # \"WeightedBinaryCrossEntropy\": ModifiedWeightedBinaryCrossEntropy(\n",
        "        #     pos_weight=torch.tensor([3.0]).to(device)\n",
        "        # ).to(device),\n",
        "        # \"WeightedFocalLoss\": WeightedFocalLoss(\n",
        "        #     alpha=0.25,\n",
        "        #     gamma=2\n",
        "        # ).to(device),\n",
        "        # \"SymmetricCrossEntropy\": SymmetricCrossEntropyLoss(\n",
        "        #     alpha=0.1,\n",
        "        #     beta=1.0\n",
        "        # ).to(device),\n",
        "        # \"SupervisedContrastiveCrossEntropyLoss\": ModifiedSupervisedContrastiveCrossEntropyLoss(\n",
        "        #     temperature=0.07,\n",
        "        #     lam=0.5\n",
        "        # ).to(device),\n",
        "        \"HuberLoss\": HuberLoss(delta=1.0).to(device)\n",
        "    }"
      ],
      "metadata": {
        "id": "4QYl8aOgeQv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 10: Evaluation Metrics"
      ],
      "metadata": {
        "id": "KNdav7JueeYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom metrics function with debugging statements\n",
        "def compute_metrics(pred):\n",
        "    print(\"Running compute_metrics...\")  # Debugging print\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(labels, preds)\n",
        "    except ValueError:\n",
        "        roc_auc = 0\n",
        "\n",
        "    metrics = {\n",
        "        'eval_accuracy': accuracy_score(labels, preds),\n",
        "        'eval_f1': f1_score(labels, preds, average='binary'),\n",
        "        'eval_precision': precision_score(labels, preds, average='binary'),\n",
        "        'eval_recall': recall_score(labels, preds, average='binary'),\n",
        "        'eval_roc_auc': roc_auc\n",
        "    }\n",
        "    # print(\"Computed metrics:\", metrics)  # Debugging print\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "apiVQJCLea9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 11: Custom Trainer"
      ],
      "metadata": {
        "id": "qG0QCJfpf1Xm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model FT (Full and layer-wise)"
      ],
      "metadata": {
        "id": "4syfZwlijTH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Trainer class with additional logging for evaluation\n",
        "class CustomTrainer(Trainer):\n",
        "    def __init__(self, *args, loss_func=None, compute_metrics=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_func = loss_func\n",
        "        self.compute_metrics = compute_metrics  # Accept compute_metrics\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        if \"labels\" in inputs:\n",
        "            # Ensure labels are on the correct device\n",
        "            if not isinstance(inputs[\"labels\"], torch.Tensor):\n",
        "                inputs[\"labels\"] = torch.tensor(inputs[\"labels\"], device=self.args.device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        if self.loss_func is not None:\n",
        "            logits = outputs.logits\n",
        "            labels = inputs[\"labels\"]\n",
        "\n",
        "            # Binary classification losses need special handling\n",
        "            if isinstance(self.loss_func, (ModifiedSquaredBCEWithLogitsLoss,\n",
        "                                           ModifiedWeightedBinaryCrossEntropy,\n",
        "                                           ModifiedBCEWithLogitsLoss)):\n",
        "                loss = self.loss_func(logits, labels)\n",
        "            else:\n",
        "                # For cross entropy based losses\n",
        "                labels = labels.long()\n",
        "                loss = self.loss_func(logits, labels)\n",
        "        else:\n",
        "            loss = outputs.loss\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    def evaluate(self, eval_dataset=None, **kwargs):\n",
        "        # Log that evaluation is being performed\n",
        "        print(\"Performing evaluation...\")\n",
        "        results = super().evaluate(eval_dataset=eval_dataset, **kwargs)\n",
        "        if self.compute_metrics is not None:\n",
        "            pass\n",
        "            # print(\"Evaluated metrics:\", results)  # Debugging print\n",
        "        else:\n",
        "          pass\n",
        "            # print(\"Warning: compute_metrics function was not used.\")\n",
        "        return results\n",
        "\n",
        "# cleanup function\n",
        "def cleanup():\n",
        "    \"\"\"Clean up GPU memory\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "7WLioVTp-P-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adaptor FT"
      ],
      "metadata": {
        "id": "wddGs793jWgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomAdapterTrainer(AdapterTrainer):\n",
        "    \"\"\"\n",
        "    Custom AdapterTrainer that supports custom loss functions and additional logging\n",
        "    Inherits from AdapterTrainer to maintain adapter-specific functionality\n",
        "    \"\"\"\n",
        "    def __init__(self, *args, loss_func=None, compute_metrics=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_func = loss_func\n",
        "        self.compute_metrics = compute_metrics\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        \"\"\"\n",
        "        Custom loss computation that supports various loss functions\n",
        "        Handles both adapter-specific behavior and custom loss functions\n",
        "        \"\"\"\n",
        "        if \"labels\" in inputs:\n",
        "            # Ensure labels are on the correct device\n",
        "            if not isinstance(inputs[\"labels\"], torch.Tensor):\n",
        "                inputs[\"labels\"] = torch.tensor(inputs[\"labels\"], device=self.args.device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        if self.loss_func is not None:\n",
        "            logits = outputs.logits\n",
        "            labels = inputs[\"labels\"]\n",
        "\n",
        "            # Binary classification losses need special handling\n",
        "            if isinstance(self.loss_func, (ModifiedSquaredBCEWithLogitsLoss,\n",
        "                                         ModifiedWeightedBinaryCrossEntropy,\n",
        "                                         ModifiedBCEWithLogitsLoss)):\n",
        "                loss = self.loss_func(logits, labels)\n",
        "            else:\n",
        "                # For cross entropy based losses\n",
        "                labels = labels.long()\n",
        "                loss = self.loss_func(logits, labels)\n",
        "\n",
        "            # Store loss for adapter-specific logging\n",
        "            if hasattr(outputs, \"loss\") and outputs.loss is not None:\n",
        "                outputs.loss = loss\n",
        "        else:\n",
        "            loss = outputs.loss\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    def evaluate(self, eval_dataset=None, **kwargs):\n",
        "        \"\"\"\n",
        "        Enhanced evaluation method with additional logging\n",
        "        \"\"\"\n",
        "        logger = logging.getLogger(__name__)\n",
        "        logger.info(\"Starting evaluation...\")\n",
        "\n",
        "        try:\n",
        "            results = super().evaluate(eval_dataset=eval_dataset, **kwargs)\n",
        "\n",
        "            # Log adapter-specific information\n",
        "            if hasattr(self.model, \"active_adapters\"):\n",
        "                active_adapters = self.model.active_adapters\n",
        "                logger.info(f\"Active adapters during evaluation: {active_adapters}\")\n",
        "\n",
        "            # Log evaluation results\n",
        "            if self.compute_metrics is not None:\n",
        "                logger.info(f\"Evaluation metrics: {results}\")\n",
        "\n",
        "                # Log to wandb if available\n",
        "                if wandb.run is not None:\n",
        "                    wandb.log({\n",
        "                        \"eval/loss\": results.get(\"eval_loss\", 0),\n",
        "                        \"eval/accuracy\": results.get(\"eval_accuracy\", 0),\n",
        "                        \"eval/f1\": results.get(\"eval_f1\", 0),\n",
        "                        \"eval/precision\": results.get(\"eval_precision\", 0),\n",
        "                        \"eval/recall\": results.get(\"eval_recall\", 0),\n",
        "                        \"eval/roc_auc\": results.get(\"eval_roc_auc\", 0)\n",
        "                    })\n",
        "            else:\n",
        "                logger.warning(\"No compute_metrics function provided for evaluation\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during evaluation: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "        return results\n",
        "\n",
        "    def log(self, logs: Dict[str, float]) -> None:\n",
        "        \"\"\"\n",
        "        Enhanced logging method to include adapter-specific information\n",
        "        \"\"\"\n",
        "        if hasattr(self.model, \"active_adapters\"):\n",
        "            logs[\"active_adapters\"] = str(self.model.active_adapters)\n",
        "\n",
        "        # Add adapter parameter counts if available\n",
        "        if hasattr(self.model, \"get_adapter_parameter_counts\"):\n",
        "            param_counts = self.model.get_adapter_parameter_counts()\n",
        "            for adapter_name, count in param_counts.items():\n",
        "                logs[f\"adapter_params/{adapter_name}\"] = count\n",
        "\n",
        "        super().log(logs)\n",
        "\n",
        "    def save_model(self, output_dir: Optional[str] = None, _internal_call: bool = False):\n",
        "        \"\"\"\n",
        "        Enhanced save method to handle both model and adapter saving\n",
        "        \"\"\"\n",
        "        # First, save the model using parent class method\n",
        "        super().save_model(output_dir, _internal_call)\n",
        "\n",
        "        # Then save active adapters separately\n",
        "        if hasattr(self.model, \"active_adapters\") and self.model.active_adapters:\n",
        "            adapter_dir = os.path.join(output_dir, \"adapters\")\n",
        "            os.makedirs(adapter_dir, exist_ok=True)\n",
        "\n",
        "            for adapter_name in self.model.active_adapters:\n",
        "                try:\n",
        "                    adapter_path = os.path.join(adapter_dir, adapter_name)\n",
        "                    self.model.save_adapter(adapter_path, adapter_name)\n",
        "                    logging.info(f\"Saved adapter {adapter_name} to {adapter_path}\")\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Failed to save adapter {adapter_name}: {str(e)}\")"
      ],
      "metadata": {
        "id": "__vcEJmejes5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 12: Model Save/Load Functions"
      ],
      "metadata": {
        "id": "oEGlYyH10F_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Optional, Callable\n",
        "\n",
        "# Create logs directory if it doesn't exist\n",
        "os.makedirs('logs', exist_ok=True)\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler(sys.stdout),  # Print to console\n",
        "        logging.FileHandler(os.path.join('logs', f'training_{time.strftime(\"%Y%m%d_%H%M%S\")}.log'))  # Save to file with timestamp\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create logger instance\n",
        "logger = logging.getLogger(\"greenland_experiments\")\n",
        "\n",
        "# Set log level\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Create handlers for both console and file output\n",
        "console_handler = logging.StreamHandler(sys.stdout)\n",
        "file_handler = logging.FileHandler(os.path.join('logs', f'training_{time.strftime(\"%Y%m%d_%H%M%S\")}.log'))\n",
        "\n",
        "# Create formatter\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Set formatter for handlers\n",
        "console_handler.setFormatter(formatter)\n",
        "file_handler.setFormatter(formatter)\n",
        "\n",
        "# Add handlers to logger\n",
        "logger.addHandler(console_handler)\n",
        "logger.addHandler(file_handler)\n",
        "\n",
        "# Ensure logger doesn't propagate to root logger\n",
        "logger.propagate = False\n",
        "\n",
        "# Function to get colored logger output (optional)\n",
        "def get_colored_logger():\n",
        "    \"\"\"Returns a logger with colored output for better readability\"\"\"\n",
        "    try:\n",
        "        import colorlog\n",
        "\n",
        "        colored_formatter = colorlog.ColoredFormatter(\n",
        "            '%(log_color)s%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "            log_colors={\n",
        "                'DEBUG': 'cyan',\n",
        "                'INFO': 'green',\n",
        "                'WARNING': 'yellow',\n",
        "                'ERROR': 'red',\n",
        "                'CRITICAL': 'red,bg_white',\n",
        "            }\n",
        "        )\n",
        "        console_handler.setFormatter(colored_formatter)\n",
        "\n",
        "    except ImportError:\n",
        "        logger.info(\"colorlog not installed. Using standard logging output.\")\n",
        "\n",
        "    return logger\n",
        "\n",
        "# Create the colored logger (optional)\n",
        "logger = get_colored_logger()\n",
        "\n",
        "def save_model_with_fallback(trainer, model_name, training_type=\"full_ft\", relation_type=None, objective=None):\n",
        "    \"\"\"\n",
        "    Attempt to save model with multiple fallback options based on training type\n",
        "\n",
        "    Args:\n",
        "        trainer: The trainer instance\n",
        "        model_name: Base name for the model/adapter/peft\n",
        "        training_type: Type of training ('full_ft', 'adapter', 'peft', 'bitfit')\n",
        "        relation_type: Type of linguistic relationship (genetic, script, word_order)\n",
        "        objective: Training objective (head_to_tail, head_and_tail, tail_to_tail)\n",
        "    \"\"\"\n",
        "    if not model_name:\n",
        "        logger.error(\"❌ Model name cannot be empty\")\n",
        "        return False\n",
        "\n",
        "    # Create timestamped version of model name with relationship and objective info\n",
        "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    relationship_info = f\"{relation_type}_{objective}\" if relation_type and objective else \"\"\n",
        "    full_model_name = f\"{model_name}_{relationship_info}_{timestamp}\" if relationship_info else f\"{model_name}_{timestamp}\"\n",
        "\n",
        "    # Helper function to get active adapter safely\n",
        "    def get_active_adapter(model):\n",
        "      if hasattr(model, 'active_adapters'):\n",
        "          active_adapters = model.active_adapters\n",
        "          if isinstance(active_adapters, (list, tuple)):\n",
        "              return active_adapters[0]\n",
        "          elif hasattr(active_adapters, 'first'):  # Handle Stack type\n",
        "              return active_adapters.first()\n",
        "          return active_adapters\n",
        "      return None\n",
        "\n",
        "    # def get_active_adapter(model):\n",
        "    #     if hasattr(model, 'active_adapters'):\n",
        "    #         active_adapters = model.active_adapters\n",
        "    #         if isinstance(active_adapters, (list, tuple)):\n",
        "    #             return active_adapters[0]\n",
        "    #         elif hasattr(active_adapters, 'first'):  # Handle Stack type\n",
        "    #             return active_adapters.first\n",
        "    #         return active_adapters\n",
        "    #     return None\n",
        "\n",
        "    try:\n",
        "        # First try to save to HuggingFace Hub\n",
        "        hub_path = f\"jslai/{full_model_name}\"\n",
        "\n",
        "        if training_type == \"full_ft\":\n",
        "            # Standard full fine-tuning save\n",
        "            trainer.push_to_hub(hub_path)\n",
        "            logger.info(f\"✅ Full fine-tuned model saved to Hugging Face Hub as {hub_path}\")\n",
        "            return True\n",
        "\n",
        "        elif training_type == \"adapter\":\n",
        "            try:\n",
        "                # Save base model\n",
        "                trainer.save_model(hub_path)\n",
        "                logger.info(f\"✅ Adapter base model saved to Hugging Face Hub as {hub_path}\")\n",
        "\n",
        "                # Save adapter\n",
        "                active_adapter = get_active_adapter(trainer.model)\n",
        "                if active_adapter:\n",
        "                    adapter_path = f\"{hub_path}/adapter\"\n",
        "                    # trainer.model.push_adapter_to_hub(repo_id=adapter_path,adapter_name=active_adapter)\n",
        "                    trainer.model.push_adapter_to_hub(repo_id=hub_path,adapter_name=active_adapter)\n",
        "                    logger.info(f\"✅ Adapter weights saved to Hugging Face Hub as {adapter_path}\")\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"⚠️ Hub adapter save error: {str(e)}\")\n",
        "                raise\n",
        "\n",
        "        elif training_type == \"peft\":\n",
        "            try:\n",
        "                # Save PEFT model and adapter\n",
        "                trainer.model.save_pretrained(hub_path)\n",
        "                logger.info(f\"✅ PEFT model saved to Hugging Face Hub as {hub_path}\")\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"⚠️ Hub PEFT save error: {str(e)}\")\n",
        "                raise\n",
        "\n",
        "        elif training_type == \"bitfit\":\n",
        "            try:\n",
        "                # Save BitFit model\n",
        "                trainer.save_model(hub_path)\n",
        "                logger.info(f\"✅ BitFit model saved to Hugging Face Hub as {hub_path}\")\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"⚠️ Hub BitFit save error: {str(e)}\")\n",
        "                raise\n",
        "\n",
        "    except Exception as hub_error:\n",
        "        logger.warning(f\"⚠️ Failed to save to Hugging Face Hub: {str(hub_error)}\")\n",
        "\n",
        "        try:\n",
        "            # Try saving to Google Drive\n",
        "            drive_path = os.path.join(drive_save_path, full_model_name)\n",
        "            os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "            if training_type == \"full_ft\":\n",
        "                trainer.save_model(drive_path)\n",
        "                logger.info(f\"✅ Full fine-tuned model saved to Google Drive at {drive_path}\")\n",
        "                return True\n",
        "\n",
        "            elif training_type == \"adapter\":\n",
        "                # Save base model\n",
        "                trainer.save_model(drive_path)\n",
        "                logger.info(f\"✅ Adapter base model saved to Google Drive at {drive_path}\")\n",
        "\n",
        "                # Save adapter\n",
        "                active_adapter = get_active_adapter(trainer.model)\n",
        "                if active_adapter:\n",
        "                    adapter_path = os.path.join(drive_path, \"adapter\")\n",
        "                    os.makedirs(adapter_path, exist_ok=True)\n",
        "                    trainer.model.save_adapter(adapter_path, active_adapter)\n",
        "                    logger.info(f\"✅ Adapter weights saved to Google Drive at {adapter_path}\")\n",
        "                return True\n",
        "\n",
        "            elif training_type == \"peft\":\n",
        "                # Save PEFT model with adapter\n",
        "                trainer.model.save_pretrained(drive_path)\n",
        "                logger.info(f\"✅ PEFT model saved to Google Drive at {drive_path}\")\n",
        "                return True\n",
        "\n",
        "            elif training_type == \"bitfit\":\n",
        "                trainer.save_model(drive_path)\n",
        "                logger.info(f\"✅ BitFit model saved to Google Drive at {drive_path}\")\n",
        "                return True\n",
        "\n",
        "        except Exception as drive_error:\n",
        "            logger.warning(f\"⚠️ Failed to save to Google Drive: {str(drive_error)}\")\n",
        "\n",
        "            try:\n",
        "                # Finally try saving locally\n",
        "                local_path = os.path.join(local_save_path, full_model_name)\n",
        "                os.makedirs(local_path, exist_ok=True)\n",
        "\n",
        "                if training_type == \"full_ft\":\n",
        "                    trainer.save_model(local_path)\n",
        "                    logger.info(f\"✅ Full fine-tuned model saved locally at {local_path}\")\n",
        "                    return True\n",
        "\n",
        "                elif training_type == \"adapter\":\n",
        "                    # Save base model\n",
        "                    trainer.save_model(local_path)\n",
        "                    logger.info(f\"✅ Adapter base model saved locally at {local_path}\")\n",
        "\n",
        "                    # Save adapter\n",
        "                    active_adapter = get_active_adapter(trainer.model)\n",
        "                    if active_adapter:\n",
        "                        adapter_path = os.path.join(local_path, \"adapter\")\n",
        "                        os.makedirs(adapter_path, exist_ok=True)\n",
        "                        trainer.model.save_adapter(adapter_path, active_adapter)\n",
        "                        logger.info(f\"✅ Adapter weights saved locally at {adapter_path}\")\n",
        "                    return True\n",
        "\n",
        "                elif training_type == \"peft\":\n",
        "                    # Save PEFT model with adapter\n",
        "                    trainer.model.save_pretrained(local_path)\n",
        "                    logger.info(f\"✅ PEFT model saved locally at {local_path}\")\n",
        "                    return True\n",
        "\n",
        "                elif training_type == \"bitfit\":\n",
        "                    trainer.save_model(local_path)\n",
        "                    logger.info(f\"✅ BitFit model saved locally at {local_path}\")\n",
        "                    return True\n",
        "\n",
        "            except Exception as local_error:\n",
        "                logger.error(f\"❌ Failed to save model anywhere: {str(local_error)}\")\n",
        "                return False\n",
        "\n",
        "    finally:\n",
        "        # Log save attempt to wandb\n",
        "        if wandb.run is not None:\n",
        "            wandb.log({\n",
        "                f\"save_attempt_{model_name}\": {\n",
        "                    \"timestamp\": timestamp,\n",
        "                    \"training_type\": training_type,\n",
        "                    \"success\": True if 'local_error' not in locals() else False,\n",
        "                    \"location\": \"hub\" if 'hub_error' not in locals() else\n",
        "                               \"drive\" if 'drive_error' not in locals() else\n",
        "                               \"local\" if 'local_error' not in locals() else \"none\",\n",
        "                    \"error\": str(local_error) if 'local_error' in locals() else\n",
        "                            str(drive_error) if 'drive_error' in locals() else\n",
        "                            str(hub_error) if 'hub_error' in locals() else None\n",
        "                }\n",
        "            })\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "def load_best_model(model_name):\n",
        "    try:\n",
        "        print(f\"Attempting to load {model_name} from Hugging Face Hub.\")\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(f\"jslai/{model_name}\")\n",
        "    except (OSError, HTTPError) as e:\n",
        "        print(f\"Failed to load {model_name} from Hugging Face Hub: {e}\")\n",
        "        try:\n",
        "            google_drive_path = os.path.join(drive_save_path, model_name)\n",
        "            if os.path.isdir(google_drive_path):\n",
        "                print(f\"Attempting to load {model_name} from Google Drive.\")\n",
        "                model = AutoModelForSequenceClassification.from_pretrained(google_drive_path)\n",
        "            else:\n",
        "                raise OSError(f\"Directory {google_drive_path} does not exist on Google Drive.\")\n",
        "        except (OSError, HTTPError) as e:\n",
        "            print(f\"Failed to load {model_name} from Google Drive: {e}\")\n",
        "            try:\n",
        "                local_path = os.path.join(local_save_path, model_name)\n",
        "                if os.path.isdir(local_path):\n",
        "                    print(f\"Attempting to load {model_name} from local storage.\")\n",
        "                    model = AutoModelForSequenceClassification.from_pretrained(local_path)\n",
        "                else:\n",
        "                    raise OSError(f\"Directory {local_path} does not exist in local storage.\")\n",
        "            except (OSError, HTTPError) as e:\n",
        "                print(f\"Failed to load {model_name} from local storage: {e}\")\n",
        "                raise FileNotFoundError(f\"Model {model_name} could not be found in any location.\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "BIpYCkc10HPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 13: Training Functions"
      ],
      "metadata": {
        "id": "Cc1yaV6t0MVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Full FT and PEFT across loss functions"
      ],
      "metadata": {
        "id": "Z0FcQ6cxwIFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def full_fine_tune_all_models(model_checkpoints, dataset, loss_functions=None, relation_type=None, objective=None):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if loss_functions is None:\n",
        "        loss_functions = get_loss_functions(device)\n",
        "\n",
        "    for model_name, model_info in model_checkpoints.items():\n",
        "        # Tokenize dataset for this model\n",
        "        try:\n",
        "            tokenized_data = tokenize_datasets(model_name, dataset)\n",
        "\n",
        "            for loss_fn_name, loss_fn in loss_functions.items():\n",
        "                print(f\"\\nTraining {model_name} with {loss_fn_name}\")\n",
        "                print(f\"Using device: {device}\")\n",
        "\n",
        "                try:\n",
        "                    # Clear CUDA cache\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                    # Initialize model\n",
        "                    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                        model_info[\"path\"],\n",
        "                        num_labels=2,\n",
        "                        problem_type=\"single_label_classification\"\n",
        "                    ).to(device)\n",
        "\n",
        "                    # Training arguments\n",
        "                    training_args = TrainingArguments(\n",
        "                        output_dir=f\"{local_save_path}/{model_name}_{loss_fn_name}_full_ft\",\n",
        "                        eval_strategy=\"epoch\",  # Updated from evaluation_strategy\n",
        "                        save_strategy=\"epoch\",\n",
        "                        learning_rate=2e-5,\n",
        "                        per_device_train_batch_size=8,\n",
        "                        per_device_eval_batch_size=8,\n",
        "                        num_train_epochs=3,\n",
        "                        weight_decay=0.01,\n",
        "                        load_best_model_at_end=True,\n",
        "                        metric_for_best_model=\"f1\",\n",
        "                        report_to=\"wandb\",\n",
        "                        logging_steps=100,\n",
        "                        fp16=True,\n",
        "                        fp16_backend=\"auto\",\n",
        "                        gradient_checkpointing=True,\n",
        "                        gradient_accumulation_steps=2,\n",
        "                        warmup_ratio=0.1,\n",
        "                        dataloader_num_workers=4,\n",
        "                        dataloader_pin_memory=True,\n",
        "                        seed=42,\n",
        "                        remove_unused_columns=False\n",
        "                    )\n",
        "\n",
        "                    # Initialize trainer\n",
        "                    trainer = CustomTrainer(\n",
        "                        model=model,\n",
        "                        args=training_args,\n",
        "                        train_dataset=tokenized_data[\"train\"],\n",
        "                        eval_dataset=tokenized_data[\"validation\"],\n",
        "                        compute_metrics=compute_metrics,\n",
        "                        loss_func=loss_fn\n",
        "\n",
        "                    )\n",
        "\n",
        "\n",
        "                    # Train and save\n",
        "                    trainer.train()\n",
        "                    # save_model_with_fallback(trainer, f\"{model_name}_{loss_fn_name}_full_ft\", training_type=\"full_ft\")\n",
        "\n",
        "                    # Save with relationship and objective info\n",
        "                    save_model_with_fallback(\n",
        "                        trainer,\n",
        "                        f\"{model_name}_{loss_fn_name}_full_ft\",\n",
        "                        training_type=\"full_ft\",\n",
        "                        relation_type=relation_type,\n",
        "                        objective=objective\n",
        "                    )\n",
        "\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error training {model_name} with {loss_fn_name}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "                finally:\n",
        "                    # Cleanup\n",
        "                    if 'trainer' in locals():\n",
        "                        del trainer\n",
        "                    if 'model' in locals():\n",
        "                        del model\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing model {model_name}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    print(\"\\nFull Fine-Tuning completed!\")\n",
        "    return\n",
        "\n",
        "\n",
        "def peft_fine_tune_all_models(model_checkpoints, dataset, loss_functions=None, peft_methods=None, relation_type=None, objective=None):\n",
        "    # Initialize device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Get loss functions if not provided\n",
        "    if loss_functions is None:\n",
        "        loss_functions = get_loss_functions(device)\n",
        "\n",
        "    def get_target_modules(model_path):\n",
        "        \"\"\"Get target modules based on model architecture\"\"\"\n",
        "        if \"bert\" in model_path.lower():\n",
        "            return [\n",
        "                f\"bert.encoder.layer.{i}.attention.self.query\" for i in range(12)\n",
        "            ] + [\n",
        "                f\"bert.encoder.layer.{i}.attention.self.key\" for i in range(12)\n",
        "            ] + [\n",
        "                f\"bert.encoder.layer.{i}.attention.self.value\" for i in range(12)\n",
        "            ] + [\n",
        "                f\"bert.encoder.layer.{i}.intermediate.dense\" for i in range(12)\n",
        "            ] + [\n",
        "                f\"bert.encoder.layer.{i}.output.dense\" for i in range(12)\n",
        "            ]\n",
        "        elif \"roberta\" in model_path.lower():\n",
        "            return [\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\", \"fc1\", \"fc2\"]\n",
        "        elif \"deberta\" in model_path.lower():\n",
        "            return [\"query_proj\", \"key_proj\", \"value_proj\", \"dense\"]\n",
        "        else:\n",
        "            return [\"query\", \"key\", \"value\", \"dense\"]\n",
        "\n",
        "    def get_feedforward_modules(model_path):\n",
        "        \"\"\"Get feedforward modules based on model architecture\"\"\"\n",
        "        if \"bert\" in model_path.lower():\n",
        "            return [f\"bert.encoder.layer.{i}.intermediate.dense\" for i in range(12)]\n",
        "        elif \"roberta\" in model_path.lower():\n",
        "            return [\"fc1\", \"fc2\"]\n",
        "        else:\n",
        "            return [\"dense\"]\n",
        "\n",
        "    # Define PEFT methods with IA3 configuration for encoder-only models\n",
        "    if peft_methods is None:\n",
        "        peft_methods = {\n",
        "            \"lora\": lambda path, modules: LoraConfig(\n",
        "                task_type=TaskType.SEQ_CLS,\n",
        "                r=16,\n",
        "                lora_alpha=32,\n",
        "                lora_dropout=0.1,\n",
        "                bias=\"none\",\n",
        "                inference_mode=False,\n",
        "                target_modules=modules,\n",
        "                modules_to_save=[\"classifier\"]\n",
        "            ),\n",
        "            \"adalora\": lambda path, modules: AdaLoraConfig(\n",
        "                task_type=TaskType.SEQ_CLS,\n",
        "                init_r=12,\n",
        "                target_r=8,\n",
        "                beta1=0.85,\n",
        "                beta2=0.95,\n",
        "                tinit=200,\n",
        "                tfinal=1000,\n",
        "                deltaT=10,\n",
        "                lora_alpha=32,\n",
        "                target_modules=modules,\n",
        "                lora_dropout=0.1,\n",
        "                inference_mode=False\n",
        "            ),\n",
        "            # Updated IA3 configuration for ENCODER_ONLY task type\n",
        "            \"ia3\": lambda path, modules: IA3Config(\n",
        "                task_type=TaskType.SEQ_CLS,  # Set for encoder-only models\n",
        "                target_modules=modules,  # Includes both attention and feedforward layers\n",
        "                feedforward_modules=[module for module in modules if \"intermediate.dense\" in module or \"fc1\" in module],  # Feedforward subset\n",
        "                modules_to_save=[\"classifier\"],  # Keep the classifier head trainable\n",
        "                inference_mode=False\n",
        "            )\n",
        "        }\n",
        "\n",
        "    # The rest of the code remains the same, iterating over models and configurations for fine-tuning\n",
        "    for model_name, model_info in model_checkpoints.items():\n",
        "        try:\n",
        "            # Get target modules for this model\n",
        "            target_modules = get_target_modules(model_info[\"path\"])\n",
        "\n",
        "            # Tokenize dataset specific to model\n",
        "            tokenized_data = tokenize_datasets(model_name, dataset)\n",
        "\n",
        "            for peft_name, peft_config_fn in peft_methods.items():\n",
        "                for loss_fn_name, loss_fn in loss_functions.items():\n",
        "                    try:\n",
        "                        print(f\"\\nFine-tuning {model_name} with PEFT ({peft_name}) using {loss_fn_name}\")\n",
        "                        print(f\"Using device: {device}\")\n",
        "\n",
        "                        # Initialize tokenizer and base model\n",
        "                        tokenizer = AutoTokenizer.from_pretrained(model_info[\"path\"])\n",
        "                        base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                            model_info[\"path\"],\n",
        "                            num_labels=2,\n",
        "                            problem_type=\"single_label_classification\"\n",
        "                        )\n",
        "\n",
        "                        # Get PEFT configuration\n",
        "                        peft_config = peft_config_fn(model_info[\"path\"], target_modules)\n",
        "\n",
        "                        # Update encoder_hidden_size for prefix tuning\n",
        "                        if peft_name == \"prefix\":\n",
        "                            peft_config.encoder_hidden_size = base_model.config.hidden_size\n",
        "\n",
        "                        # Get PEFT model\n",
        "                        model = get_peft_model(base_model, peft_config)\n",
        "                        print(f\"\\nTrainable parameters for {peft_name}:\")\n",
        "                        model.print_trainable_parameters()\n",
        "\n",
        "                        # Move model to device\n",
        "                        model = model.to(device)\n",
        "\n",
        "                        # Ensure loss function is on correct device\n",
        "                        loss_fn = loss_fn.to(device)\n",
        "\n",
        "                        # Define training arguments\n",
        "                        training_args = TrainingArguments(\n",
        "                            output_dir=f\"{local_save_path}/{model_name}_{loss_fn_name}_{peft_name}\",\n",
        "                            eval_strategy=\"epoch\",\n",
        "                            save_strategy=\"epoch\",\n",
        "                            learning_rate=2e-5,\n",
        "                            per_device_train_batch_size=8,\n",
        "                            per_device_eval_batch_size=8,\n",
        "                            num_train_epochs=3,\n",
        "                            weight_decay=0.01,\n",
        "                            load_best_model_at_end=True,\n",
        "                            metric_for_best_model=\"f1\",\n",
        "                            logging_dir=\"./logs\",\n",
        "                            report_to=\"wandb\",\n",
        "                            logging_steps=100,\n",
        "                            fp16=True,\n",
        "                            fp16_backend=\"auto\",\n",
        "                            gradient_checkpointing=True,\n",
        "                            gradient_accumulation_steps=4,\n",
        "                            optim=\"adamw_torch\",\n",
        "                            warmup_ratio=0.1,\n",
        "                            dataloader_num_workers=4,\n",
        "                            dataloader_pin_memory=True,\n",
        "                            seed=42\n",
        "                        )\n",
        "\n",
        "                        # Initialize trainer\n",
        "                        trainer = CustomTrainer(\n",
        "                            model=model,\n",
        "                            args=training_args,\n",
        "                            train_dataset=tokenized_data[\"train\"],\n",
        "                            eval_dataset=tokenized_data[\"validation\"],\n",
        "                            # tokenizer=tokenizer,\n",
        "                            data_collator=DataCollatorWithPadding(tokenizer),\n",
        "                            compute_metrics=compute_metrics,\n",
        "                            loss_func=loss_fn\n",
        "                        )\n",
        "\n",
        "                        # Train the model\n",
        "                        trainer.train()\n",
        "\n",
        "                        # Save the model and adapter\n",
        "                        # output_dir = f\"{local_save_path}/{model_name}_{loss_fn_name}_{peft_name}\"\n",
        "                        # save_model_with_fallback(trainer, output_dir)\n",
        "                        # model.save_pretrained(f\"{output_dir}/adapter\")\n",
        "                        # save_model_with_fallback(trainer, f\"{model_name}_{loss_fn_name}_{peft_name}\", training_type=\"peft\")\n",
        "\n",
        "                        # Save with relationship and objective info\n",
        "                        save_model_with_fallback(\n",
        "                            trainer,\n",
        "                            f\"{model_name}_{loss_fn_name}_{peft_name}\",\n",
        "                            training_type=\"peft\",\n",
        "                            relation_type=relation_type,\n",
        "                            objective=objective\n",
        "                        )\n",
        "\n",
        "                        # Clear memory\n",
        "                        del model, base_model\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error training {model_name} with {peft_name} and {loss_fn_name}: {str(e)}\")\n",
        "                        continue\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing model {model_name}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    print(\"\\nPEFT fine-tuning completed!\")\n",
        "    return\n"
      ],
      "metadata": {
        "id": "qeOK06xo3zxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BitFit UbitFit and SBitFit PEFT"
      ],
      "metadata": {
        "id": "0e0r5BXwxAfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_standard_bitfit(model):\n",
        "   for name, param in model.named_parameters():\n",
        "       param.requires_grad = 'bias' in name\n",
        "\n",
        "def apply_u_bitfit(model, train_dataloader, k=100):\n",
        "    model.zero_grad()\n",
        "    # Ensure classifier parameters are always trainable\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'classifier' in name:\n",
        "            param.requires_grad = True\n",
        "\n",
        "    importance_scores = {name: 0.0 for name, param in model.named_parameters()\n",
        "                        if 'bias' in name and 'classifier' not in name}\n",
        "    model.train()\n",
        "\n",
        "    # Process one batch to calculate importance scores\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch['input_ids'].to(model.device)\n",
        "        attention_mask = batch['attention_mask'].to(model.device)\n",
        "        labels = batch['labels'].to(model.device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'bias' in name and param.grad is not None and 'classifier' not in name:\n",
        "                importance_scores[name] += (param * param.grad).abs().sum().item()\n",
        "        break\n",
        "\n",
        "    # Select top k parameters\n",
        "    top_k_params = sorted(importance_scores.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "    top_k_names = [name for name, _ in top_k_params]\n",
        "\n",
        "    # Set requires_grad\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'classifier' not in name:  # Don't modify classifier params\n",
        "            param.requires_grad = name in top_k_names\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "def apply_s_bitfit(model, train_dataloader, k=2):\n",
        "    model.zero_grad()\n",
        "    # Ensure classifier parameters are always trainable\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'classifier' in name:\n",
        "            param.requires_grad = True\n",
        "\n",
        "    layer_importance = {}\n",
        "    model.train()\n",
        "\n",
        "    # Process one batch to calculate layer importance\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch['input_ids'].to(model.device)\n",
        "        attention_mask = batch['attention_mask'].to(model.device)\n",
        "        labels = batch['labels'].to(model.device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'bias' in name and 'classifier' not in name:\n",
        "                layer_name = name.rsplit('.', 2)[0]\n",
        "                if layer_name not in layer_importance:\n",
        "                    layer_importance[layer_name] = 0.0\n",
        "                layer_importance[layer_name] += (param * param.grad).abs().sum().item()\n",
        "        break\n",
        "\n",
        "    # Select top k layers\n",
        "    top_k_layers = sorted(layer_importance.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "    top_k_layer_names = [name for name, _ in top_k_layers]\n",
        "\n",
        "    # Set requires_grad\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'classifier' not in name:  # Don't modify classifier params\n",
        "            layer_name = name.rsplit('.', 2)[0]\n",
        "            param.requires_grad = layer_name in top_k_layer_names\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "def bitfit_peft_fine_tune_all_models(model_checkpoints, dataset, loss_functions=None, peft_method=None, k=100, relation_type=None, objective=None):\n",
        "   device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "   if loss_functions is None:\n",
        "       loss_functions = get_loss_functions(device)\n",
        "\n",
        "   for model_name, model_info in model_checkpoints.items():\n",
        "       try:\n",
        "           print(f\"\\nProcessing {model_name} with {peft_method}\")\n",
        "           tokenized_data = tokenize_datasets(model_name, dataset)\n",
        "           tokenizer = AutoTokenizer.from_pretrained(model_info[\"path\"])\n",
        "\n",
        "           for loss_fn_name, loss_fn in loss_functions.items():\n",
        "               try:\n",
        "                   print(f\"\\nTraining with {loss_fn_name}\")\n",
        "                   if torch.cuda.is_available():\n",
        "                       torch.cuda.empty_cache()\n",
        "\n",
        "                   model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                       model_info[\"path\"],\n",
        "                       num_labels=2,\n",
        "                       problem_type=\"single_label_classification\"\n",
        "                   ).to(device)\n",
        "\n",
        "                   dataloader = DataLoader(\n",
        "                    tokenized_data[\"train\"],\n",
        "                    batch_size=8,\n",
        "                    shuffle=True,\n",
        "                    num_workers=4,\n",
        "                    pin_memory=True,\n",
        "                    collate_fn=DataCollatorWithPadding(tokenizer)  # Add this line\n",
        "                    )\n",
        "\n",
        "\n",
        "                   if peft_method == \"BitFit Full Fine-Tuning\":\n",
        "                       apply_standard_bitfit(model)\n",
        "                   elif peft_method == \"U-BitFit\":\n",
        "                       apply_u_bitfit(model, dataloader, k)\n",
        "                   elif peft_method == \"S-BitFit\":\n",
        "                       apply_s_bitfit(model, dataloader, k=2)\n",
        "\n",
        "                   training_args = TrainingArguments(\n",
        "                       output_dir=f\"{local_save_path}/{model_name}_{peft_method}_{loss_fn_name}\",\n",
        "                       eval_strategy=\"epoch\",\n",
        "                       save_strategy=\"epoch\",\n",
        "                       learning_rate=2e-5,\n",
        "                       per_device_train_batch_size=8,\n",
        "                       per_device_eval_batch_size=8,\n",
        "                       num_train_epochs=3,\n",
        "                       weight_decay=0.01,\n",
        "                       load_best_model_at_end=True,\n",
        "                       metric_for_best_model=\"f1\",\n",
        "                       report_to=\"wandb\",\n",
        "                       logging_steps=100,\n",
        "                       fp16=True,\n",
        "                       fp16_backend=\"auto\",\n",
        "                       gradient_checkpointing=True,\n",
        "                       gradient_accumulation_steps=2,\n",
        "                       warmup_ratio=0.1,\n",
        "                       dataloader_num_workers=4,\n",
        "                       dataloader_pin_memory=True,\n",
        "                       seed=42,\n",
        "                       remove_unused_columns=False\n",
        "                   )\n",
        "\n",
        "                   trainer = CustomTrainer(\n",
        "                       model=model,\n",
        "                       args=training_args,\n",
        "                       train_dataset=tokenized_data[\"train\"],\n",
        "                       eval_dataset=tokenized_data[\"validation\"],\n",
        "                       tokenizer=tokenizer,\n",
        "                       data_collator=DataCollatorWithPadding(tokenizer),\n",
        "                       compute_metrics=compute_metrics,\n",
        "                       loss_func=loss_fn\n",
        "                   )\n",
        "                   # Train and save\n",
        "                   trainer.train()\n",
        "\n",
        "                  #  save_model_with_fallback(trainer, f\"{model_name}_{peft_method}_{loss_fn_name}\")\n",
        "                  #  save_model_with_fallback(trainer, f\"{model_name}_{peft_method}_{loss_fn_name}\", training_type=\"bitfit\")\n",
        "\n",
        "                   # Save with relationship and objective info\n",
        "                   save_model_with_fallback(\n",
        "                        trainer,\n",
        "                        f\"{model_name}_{peft_method}_{loss_fn_name}\",\n",
        "                        training_type=\"bitfit\",\n",
        "                        relation_type=relation_type,\n",
        "                        objective=objective\n",
        "                      )\n",
        "\n",
        "               except Exception as e:\n",
        "                   print(f\"Error training with {loss_fn_name}: {str(e)}\")\n",
        "                   continue\n",
        "\n",
        "               finally:\n",
        "                   if 'trainer' in locals():\n",
        "                       del trainer\n",
        "                   if 'model' in locals():\n",
        "                       del model\n",
        "                   if torch.cuda.is_available():\n",
        "                       torch.cuda.empty_cache()\n",
        "\n",
        "       except Exception as e:\n",
        "           print(f\"Error processing {model_name}: {str(e)}\")\n",
        "           continue\n",
        "\n",
        "   print(f\"\\n{peft_method} completed!\")\n",
        "   return"
      ],
      "metadata": {
        "id": "hkj7DF29xI6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adaptor PEFT"
      ],
      "metadata": {
        "id": "vrQ9nxt9c_w9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import wandb\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Optional, Callable\n",
        "from transformers import TrainingArguments, EarlyStoppingCallback\n",
        "\n",
        "\n",
        "def adapter_fine_tune_all_models(\n",
        "    model_checkpoints: Dict[str, Dict[str, Any]],\n",
        "    dataset: Any,\n",
        "    loss_functions: Optional[Dict[str, Callable]] = None,\n",
        "    local_save_path: str = \"./adapter_checkpoints\",\n",
        "    relation_type=None, objective=None\n",
        ") -> None:\n",
        "    \"\"\"Fine-tune models using all supported adapter configurations\"\"\"\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    loss_functions = loss_functions or {\"default\": None}\n",
        "\n",
        "    # Define comprehensive adapter configurations\n",
        "    adapter_configs = {\n",
        "        \"seq_bn\": SeqBnConfig(),  # Sequential bottleneck adapter\n",
        "        \"double_seq_bn\": DoubleSeqBnConfig(),  # Double sequential bottleneck\n",
        "        \"par_bn\": ParBnConfig(),  # Parallel bottleneck\n",
        "        \"scaled_par_bn\": ParBnConfig(scaling=\"learned\"),  # Scaled parallel bottleneck\n",
        "        \"seq_bn_inv\": SeqBnInvConfig(),  # Sequential invertible adapter\n",
        "        \"double_seq_bn_inv\": DoubleSeqBnInvConfig(),  # Double sequential invertible\n",
        "        \"compacter\": CompacterConfig(),  # Compacter\n",
        "        \"compacter++\": CompacterPlusPlusConfig(),  # Compacter++\n",
        "        \"prefix_tuning\": PrefixTuningConfig(),  # Standard prefix tuning\n",
        "        # \"prefix_tuning_flat\": PrefixTuningConfig(flat=True),  # Flat prefix tuning\n",
        "        \"lora\": LoRAConfig(),  # LoRA\n",
        "        \"ia3\": IA3Config(),  # IA³\n",
        "        \"mam\": MAMConfig(),  # Mix-and-Match\n",
        "        \"unipelt\": UniPELTConfig(),  # UniPELT\n",
        "        \"prompt_tuning\": PromptTuningConfig(),  # Prompt Tuning\n",
        "        \"loreft\": LoReftConfig(),  # ReFT\n",
        "        \"noreft\": NoReftConfig(),  # NoReFT\n",
        "        \"direft\": DiReftConfig()  # DiReFT\n",
        "    }\n",
        "\n",
        "    for model_name, model_info in model_checkpoints.items():\n",
        "        logger.info(f\"\\nProcessing {model_name}\")\n",
        "\n",
        "        try:\n",
        "            tokenized_data = tokenize_datasets(model_name, dataset)\n",
        "\n",
        "            for adapter_name, adapter_config in adapter_configs.items():\n",
        "                for loss_fn_name, loss_fn in loss_functions.items():\n",
        "                    try:\n",
        "                        logger.info(f\"\\nTraining with {adapter_name} adapter and {loss_fn_name}\")\n",
        "\n",
        "                        if torch.cuda.is_available():\n",
        "                            torch.cuda.empty_cache()\n",
        "\n",
        "                        # Initialize model with AutoAdapterModel\n",
        "                        model = AutoAdapterModel.from_pretrained(\n",
        "                            model_info[\"path\"],\n",
        "                            num_labels=2,\n",
        "                            trust_remote_code=True\n",
        "                        ).to(device)\n",
        "\n",
        "                        # Add adapter with specific configuration\n",
        "                        adapter_id = f\"{model_name}_{adapter_name}\"\n",
        "                        model.add_adapter(adapter_id, config=adapter_config)\n",
        "\n",
        "                        # Add classification head\n",
        "                        model.add_classification_head(\n",
        "                            adapter_id,\n",
        "                            num_labels=2,\n",
        "                            id2label={0: \"False\", 1: \"True\"}\n",
        "                        )\n",
        "\n",
        "                        # Activate the adapter\n",
        "                        # model.set_active_adapters(adapter_id)\n",
        "\n",
        "                        # Activate adapter for training\n",
        "                        model.train_adapter(adapter_id)\n",
        "\n",
        "                        # Training arguments with adapter-specific settings\n",
        "                        training_args = TrainingArguments(\n",
        "                            output_dir=f\"{local_save_path}/{model_name}_{adapter_name}_{loss_fn_name}\",\n",
        "                            learning_rate=1e-4,\n",
        "                            num_train_epochs=6,\n",
        "                            per_device_train_batch_size=32,\n",
        "                            per_device_eval_batch_size=32,\n",
        "                            logging_steps=200,\n",
        "                            save_strategy=\"epoch\",\n",
        "                            eval_strategy=\"epoch\",\n",
        "                            load_best_model_at_end=True,\n",
        "                            metric_for_best_model=\"eval_loss\",\n",
        "                            greater_is_better=False,\n",
        "                            remove_unused_columns=False,\n",
        "                            fp16=True,\n",
        "                            gradient_checkpointing=False,\n",
        "                            warmup_ratio=0.1,\n",
        "                            weight_decay=0.01,\n",
        "                            report_to=\"wandb\"\n",
        "                        )\n",
        "\n",
        "                        # Initialize AdapterTrainer\n",
        "                        trainer = CustomAdapterTrainer(\n",
        "                            model=model,\n",
        "                            args=training_args,\n",
        "                            train_dataset=tokenized_data[\"train\"],\n",
        "                            eval_dataset=tokenized_data[\"validation\"],\n",
        "                            compute_metrics=compute_metrics,\n",
        "                            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "                        )\n",
        "\n",
        "                        # Train\n",
        "                        trainer.train()\n",
        "\n",
        "                        # Save using existing save_model_with_fallback function\n",
        "                        # model_save_name = f\"{model_name}_{adapter_name}_{loss_fn_name}\"\n",
        "                        # save_model_with_fallback(trainer, model_save_name, training_type=\"adapter\")\n",
        "\n",
        "\n",
        "                        # Save with relationship and objective info\n",
        "                        model_save_name = f\"{model_name}_{adapter_name}_{loss_fn_name}\"\n",
        "                        save_model_with_fallback(\n",
        "                            trainer,\n",
        "                            model_save_name,\n",
        "                            training_type=\"adapter\",\n",
        "                            relation_type=relation_type,\n",
        "                            objective=objective\n",
        "                        )\n",
        "\n",
        "\n",
        "                        # Also save the adapter weights separately\n",
        "                        try:\n",
        "                            adapter_save_path = os.path.join(local_save_path, f\"{model_save_name}_adapter\")\n",
        "                            model.save_adapter(adapter_save_path, adapter_id)\n",
        "                            logger.info(f\"Adapter weights saved to {adapter_save_path}\")\n",
        "                        except Exception as e:\n",
        "                            logger.warning(f\"Failed to save adapter weights: {str(e)}\")\n",
        "\n",
        "                        # Log adapter size to wandb if available\n",
        "                        try:\n",
        "                            adapter_size = Path(adapter_save_path).stat().st_size / (1024 * 1024)  # Size in MB\n",
        "                            wandb.log({f\"{adapter_name}_size_mb\": adapter_size})\n",
        "                        except Exception as e:\n",
        "                            logger.warning(f\"Failed to log adapter size: {str(e)}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error training {model_name} with {adapter_name} and {loss_fn_name}: {str(e)}\")\n",
        "                        continue\n",
        "\n",
        "                    finally:\n",
        "                        if 'model' in locals():\n",
        "                            del model\n",
        "                        if torch.cuda.is_available():\n",
        "                            torch.cuda.empty_cache()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing {model_name}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    logger.info(\"\\nAdapter fine-tuning completed!\")\n"
      ],
      "metadata": {
        "id": "cohcYcr3ieUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mixmatch_Adapter"
      ],
      "metadata": {
        "id": "M4aOTpA7l0ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def mixmatch_adapter_fine_tune(model_checkpoints, dataset, loss_functions=None):\n",
        "#     \"\"\"Fine-tune models using Mix-and-Match adapter configurations\"\"\"\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#     if loss_functions is None:\n",
        "#         loss_functions = get_loss_functions(device)\n",
        "\n",
        "#     # Define Mix-and-Match configurations\n",
        "#     mixmatch_configs = {\n",
        "#         \"mam_basic\": lambda: MAMConfig(\n",
        "#             bottleneck_size=800\n",
        "#         ),\n",
        "#         \"mam_custom\": lambda: ConfigUnion(\n",
        "#             PrefixTuningConfig(bottleneck_size=800, prefix_length=30),\n",
        "#             ParBnConfig(reduction_factor=16)\n",
        "#         ),\n",
        "#         \"unipelt_basic\": lambda: UniPELTConfig(),\n",
        "#         \"unipelt_custom\": lambda: ConfigUnion(\n",
        "#             LoRAConfig(r=8, alpha=2, use_gating=True),\n",
        "#             PrefixTuningConfig(prefix_length=30, use_gating=True),\n",
        "#             SeqBnConfig(reduction_factor=16, use_gating=True)\n",
        "#         )\n",
        "#     }\n",
        "\n",
        "#     for model_name, model_info in model_checkpoints.items():\n",
        "#         try:\n",
        "#             print(f\"\\nProcessing {model_name}\")\n",
        "#             tokenized_data = tokenize_datasets(model_name, dataset)\n",
        "\n",
        "#             for config_name, config_fn in mixmatch_configs.items():\n",
        "#                 for loss_fn_name, loss_fn in loss_functions.items():\n",
        "#                     try:\n",
        "#                         print(f\"\\nTraining with {config_name} configuration and {loss_fn_name}\")\n",
        "\n",
        "#                         # Initialize model\n",
        "#                         model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#                             model_info[\"path\"],\n",
        "#                             num_labels=2\n",
        "#                         ).to(device)\n",
        "\n",
        "#                         # Add adapter with mix-match configuration\n",
        "#                         adapter_config = config_fn()\n",
        "#                         model.add_adapter(f\"{config_name}_adapter\", config=adapter_config)\n",
        "#                         model.train_adapter(f\"{config_name}_adapter\")\n",
        "\n",
        "#                         # Add gating callback for UniPELT configurations\n",
        "#                         callbacks = []\n",
        "#                         if \"unipelt\" in config_name:\n",
        "#                             callbacks.append(GatingScoreCallback)\n",
        "\n",
        "#                         # Training arguments\n",
        "#                         training_args = TrainingArguments(\n",
        "#                             output_dir=f\"{local_save_path}/{model_name}_{config_name}_{loss_fn_name}\",\n",
        "#                             eval_strategy=\"epoch\",\n",
        "#                             save_strategy=\"epoch\",\n",
        "#                             learning_rate=2e-5,\n",
        "#                             per_device_train_batch_size=8,\n",
        "#                             per_device_eval_batch_size=8,\n",
        "#                             num_train_epochs=3,\n",
        "#                             weight_decay=0.01,\n",
        "#                             load_best_model_at_end=True,\n",
        "#                             metric_for_best_model=\"f1\",\n",
        "#                             logging_dir=\"./logs\",\n",
        "#                             report_to=\"wandb\",\n",
        "#                             logging_steps=100,\n",
        "#                             fp16=True,\n",
        "#                             gradient_checkpointing=True,\n",
        "#                             gradient_accumulation_steps=4,\n",
        "#                             warmup_ratio=0.1\n",
        "#                         )\n",
        "\n",
        "#                         # Initialize trainer\n",
        "#                         trainer = CustomTrainer(\n",
        "#                             model=model,\n",
        "#                             args=training_args,\n",
        "#                             train_dataset=tokenized_data[\"train\"],\n",
        "#                             eval_dataset=tokenized_data[\"validation\"],\n",
        "#                             compute_metrics=compute_metrics,\n",
        "#                             loss_func=loss_fn,\n",
        "#                             callbacks=callbacks\n",
        "#                         )\n",
        "\n",
        "#                         # Train\n",
        "#                         trainer.train()\n",
        "\n",
        "#                         # Save adapter and additional data\n",
        "#                         output_dir = f\"{local_save_path}/{model_name}_{config_name}_{loss_fn_name}\"\n",
        "#                         model.save_all_adapters(output_dir)\n",
        "\n",
        "#                         # Save gating scores for UniPELT\n",
        "#                         if \"unipelt\" in config_name:\n",
        "#                             outputs = trainer.model(\n",
        "#                                 **trainer.model.dummy_inputs,\n",
        "#                                 output_adapter_gating_scores=True\n",
        "#                             )\n",
        "#                             if hasattr(outputs, \"adapter_gating_scores\"):\n",
        "#                                 with open(f\"{output_dir}/gating_scores.pkl\", \"wb\") as f:\n",
        "#                                     pickle.dump(outputs.adapter_gating_scores, f)\n",
        "\n",
        "#                     except Exception as e:\n",
        "#                         print(f\"Error training {model_name} with {config_name} and {loss_fn_name}: {str(e)}\")\n",
        "#                         continue\n",
        "\n",
        "#                     finally:\n",
        "#                         cleanup()\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error processing {model_name}: {str(e)}\")\n",
        "#             continue\n",
        "\n",
        "#     print(\"\\nMix-Match adapter fine-tuning completed!\")\n",
        "#     return"
      ],
      "metadata": {
        "id": "Zg2nXtTYlynP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "                        # Save the model and adapter\n",
        "                        # output_dir = f\"{local_save_path}/{model_name}_{loss_fn_name}_{peft_name}\"\n",
        "                        # save_model_with_fallback(trainer, output_dir)\n",
        "                        # model.save_pretrained(f\"{output_dir}/adapter\")\n"
      ],
      "metadata": {
        "id": "reQD5jTeZbJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 14: Inference Function"
      ],
      "metadata": {
        "id": "qrJUwA9K3vct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def run_inference_and_save_results(model_checkpoints, test_df, results_dir):\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     predictions_df_list = []\n",
        "\n",
        "#     # Get list of all trained models\n",
        "#     loss_functions = get_loss_functions(device)\n",
        "\n",
        "#     for model_name, model_info in model_checkpoints.items():\n",
        "#         # For each training method (full fine-tuning with different loss functions)\n",
        "#         for loss_fn_name in loss_functions.keys():\n",
        "#             try:\n",
        "#                 # Full fine-tuning model\n",
        "#                 full_ft_model_name = f\"{model_name}_{loss_fn_name}_full_ft\"\n",
        "#                 model = load_best_model(full_ft_model_name).to(device)\n",
        "#                 tokenizer = AutoTokenizer.from_pretrained(model_info[\"path\"])\n",
        "\n",
        "#                 inputs = tokenizer(\n",
        "#                     list(test_df[\"text\"]),\n",
        "#                     truncation=True,\n",
        "#                     padding=True,\n",
        "#                     max_length=model_info[\"max_length\"],\n",
        "#                     return_tensors=\"pt\"\n",
        "#                 ).to(device)\n",
        "\n",
        "#                 with torch.no_grad():\n",
        "#                     outputs = model(**inputs)\n",
        "#                     preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "#                 result_df = test_df.copy()\n",
        "#                 result_df[\"prediction\"] = preds\n",
        "#                 predictions_df_list.append((full_ft_model_name, result_df))\n",
        "\n",
        "#                 # PEFT model\n",
        "#                 peft_model_name = f\"{model_name}_{loss_fn_name}_peft_lora\"\n",
        "#                 peft_model_path = os.path.join(local_save_path, peft_model_name, \"adapter\")\n",
        "\n",
        "#                 if os.path.exists(peft_model_path):\n",
        "#                     model = load_best_model(peft_model_name).to(device)\n",
        "\n",
        "#                     with torch.no_grad():\n",
        "#                         outputs = model(**inputs)\n",
        "#                         preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "#                     result_df = test_df.copy()\n",
        "#                     result_df[\"prediction\"] = preds\n",
        "#                     predictions_df_list.append((peft_model_name, result_df))\n",
        "\n",
        "#                 # Clear memory\n",
        "#                 del model\n",
        "#                 torch.cuda.empty_cache()\n",
        "\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error during inference for {model_name}: {e}\")\n",
        "#                 continue\n",
        "\n",
        "#     # Save all predictions\n",
        "#     for model_name, result_df in predictions_df_list:\n",
        "#         result_file_path = os.path.join(results_dir, f\"{model_name}_predictions.csv\")\n",
        "#         result_df.to_csv(result_file_path, index=False)\n",
        "#         print(f\"Saved predictions for {model_name} to {result_file_path}\")\n"
      ],
      "metadata": {
        "id": "UJAA6rer39gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference_and_save_results(model_checkpoints, test_df, results_dir):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    predictions_df_list = []\n",
        "\n",
        "    loss_functions = get_loss_functions(device)\n",
        "\n",
        "    for model_name, model_info in model_checkpoints.items():\n",
        "        # For each training method\n",
        "        training_methods = {\n",
        "            \"full_ft\": \"_full_ft\",\n",
        "            \"lora\": \"_peft_lora\",\n",
        "            \"bitfit\": [\"_BitFit_Full_Fine-Tuning\", \"_U-BitFit\", \"_S-BitFit\"],\n",
        "            \"adapter\": \"_combined_adapter\"\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_info[\"path\"])\n",
        "            inputs = tokenizer(\n",
        "                list(test_df[\"text\"]),\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=model_info[\"max_length\"],\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(device)\n",
        "\n",
        "            for method, suffix in training_methods.items():\n",
        "                if isinstance(suffix, list):\n",
        "                    # Handle multiple variants (BitFit)\n",
        "                    for variant_suffix in suffix:\n",
        "                        try:\n",
        "                            model_path = f\"{model_name}{variant_suffix}\"\n",
        "                            if method == \"adapter\":\n",
        "                                # Load adapter model\n",
        "                                model = AutoAdapterModel.from_pretrained(\n",
        "                                    model_info[\"path\"],\n",
        "                                    num_labels=2\n",
        "                                ).to(device)\n",
        "                                model.load_adapter(f\"{local_save_path}/{model_path}/custom_adapter\")\n",
        "                                model.load_adapter_fusion(f\"{local_save_path}/{model_path}/fusion\")\n",
        "                                model.set_active_adapters([\"custom_adapter\"])\n",
        "                            else:\n",
        "                                # Load regular model\n",
        "                                model = load_best_model(model_path).to(device)\n",
        "\n",
        "                            with torch.no_grad():\n",
        "                                outputs = model(**inputs)\n",
        "                                preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "                            result_df = test_df.copy()\n",
        "                            result_df[\"prediction\"] = preds\n",
        "                            predictions_df_list.append((f\"{model_path}\", result_df))\n",
        "\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error during inference for {model_path}: {e}\")\n",
        "                            continue\n",
        "                else:\n",
        "                    # Handle single method\n",
        "                    try:\n",
        "                        model_path = f\"{model_name}{suffix}\"\n",
        "                        if method == \"adapter\":\n",
        "                            model = AutoAdapterModel.from_pretrained(\n",
        "                                model_info[\"path\"],\n",
        "                                num_labels=2\n",
        "                            ).to(device)\n",
        "                            model.load_adapter(f\"{local_save_path}/{model_path}/custom_adapter\")\n",
        "                            model.load_adapter_fusion(f\"{local_save_path}/{model_path}/fusion\")\n",
        "                            model.set_active_adapters([\"custom_adapter\"])\n",
        "                        else:\n",
        "                            model = load_best_model(model_path).to(device)\n",
        "\n",
        "                        with torch.no_grad():\n",
        "                            outputs = model(**inputs)\n",
        "                            preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "                        result_df = test_df.copy()\n",
        "                        result_df[\"prediction\"] = preds\n",
        "                        predictions_df_list.append((f\"{model_path}\", result_df))\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error during inference for {model_path}: {e}\")\n",
        "                        continue\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing model {model_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Save all predictions\n",
        "    for model_name, result_df in predictions_df_list:\n",
        "        result_file_path = os.path.join(results_dir, f\"{model_name}_predictions.csv\")\n",
        "        result_df.to_csv(result_file_path, index=False)\n",
        "        print(f\"Saved predictions for {model_name} to {result_file_path}\")"
      ],
      "metadata": {
        "id": "0cPdyeEyYsHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 15: Main Execution"
      ],
      "metadata": {
        "id": "ArJQvEKVrPUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def main():\n",
        "#     \"\"\"Main execution function for adapter fine-tuning experiments\"\"\"\n",
        "#     # Set up logging configuration first\n",
        "#     logging.basicConfig(\n",
        "#         level=logging.INFO,\n",
        "#         format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "#         handlers=[\n",
        "#             logging.StreamHandler(),  # Print to console\n",
        "#             logging.FileHandler('experiment.log')  # Save to file\n",
        "#         ]\n",
        "#     )\n",
        "#     # Create logger instance\n",
        "#     logger = logging.getLogger(\"greenland_experiments\")\n",
        "\n",
        "#     # Initialize device\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     logger.info(f\"Using device: {device}\")\n",
        "\n",
        "#     # Log GPU information if available\n",
        "#     if torch.cuda.is_available():\n",
        "#         logger.info(f\"GPU: {torch.cuda.get_device_name()}\")\n",
        "#         logger.info(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "#     # Initialize loss functions\n",
        "#     loss_functions = get_loss_functions(device)\n",
        "#     logger.info(f\"Initialized loss functions: {list(loss_functions.keys())}\")\n",
        "\n",
        "#     # Define experiment configurations FIRST\n",
        "#     experiment_config = {\n",
        "#         \"full_fine_tuning\": {\n",
        "#             \"enabled\": False,\n",
        "#             \"name\": \"Full Fine-Tuning\",\n",
        "#             \"function\": full_fine_tune_all_models,\n",
        "#             \"args\": {\n",
        "#                 \"model_checkpoints\": model_checkpoints,\n",
        "#                 \"dataset\": dataset,\n",
        "#                 \"loss_functions\": loss_functions\n",
        "#             }\n",
        "#         },\n",
        "#         \"adapter\": {\n",
        "#             \"enabled\": True,\n",
        "#             \"name\": \"Adapter Fine-Tuning\",\n",
        "#             \"function\": adapter_fine_tune_all_models,\n",
        "#             \"args\": {\n",
        "#                 \"model_checkpoints\": model_checkpoints,\n",
        "#                 \"dataset\": dataset,\n",
        "#                 \"loss_functions\": loss_functions,\n",
        "#             }\n",
        "#         },\n",
        "#         \"hugging_face_peft\": {\n",
        "#             \"enabled\": False,\n",
        "#             \"name\": \"LoRA Adaptation\",\n",
        "#             \"function\": peft_fine_tune_all_models,\n",
        "#             \"args\": {\n",
        "#                 \"model_checkpoints\": model_checkpoints,\n",
        "#                 \"dataset\": dataset,\n",
        "#                 \"loss_functions\": loss_functions,\n",
        "#             }\n",
        "#         },\n",
        "#         \"bitfit\": {\n",
        "#             \"enabled\": False,\n",
        "#             \"name\": \"BitFit Variants\",\n",
        "#             \"variants\": [\"BitFit Full Fine-Tuning\", \"U-BitFit\", \"S-BitFit\"],\n",
        "#             \"function\": bitfit_peft_fine_tune_all_models,\n",
        "#             \"args\": {\n",
        "#                 \"model_checkpoints\": model_checkpoints,\n",
        "#                 \"dataset\": dataset,\n",
        "#                 \"loss_functions\": loss_functions,\n",
        "#                 \"k\": 100\n",
        "#             }\n",
        "#         }\n",
        "#     }\n",
        "\n",
        "#     # THEN calculate total combinations for each approach\n",
        "#     total_count = {\n",
        "#         \"full_fine_tuning\": len(model_checkpoints) * len(loss_functions),\n",
        "#         \"adapter\": len(model_checkpoints) * len(loss_functions) * 18,  # 18 adapter techniques\n",
        "#         \"hugging_face_peft\": len(model_checkpoints) * len(loss_functions) * 4,  # 4 PEFT techniques\n",
        "#         \"bitfit\": len(model_checkpoints) * len(loss_functions) * 3  # 3 BitFit variants\n",
        "#     }\n",
        "\n",
        "#     # Print experiment plan\n",
        "#     logger.info(\"\\n\" + \"=\"*50)\n",
        "#     logger.info(\"EXPERIMENT PLAN\")\n",
        "#     logger.info(\"=\"*50)\n",
        "\n",
        "#     # Log enabled experiments\n",
        "#     enabled_experiments = [config[\"name\"] for name, config in experiment_config.items() if config[\"enabled\"]]\n",
        "#     logger.info(f\"Enabled experiments: {enabled_experiments}\")\n",
        "\n",
        "#     try:\n",
        "#         # Initialize wandb run with configuration\n",
        "#         wandb.init(\n",
        "#             project=\"greenland\",\n",
        "#             config={\n",
        "#                 \"device\": str(device),\n",
        "#                 \"enabled_experiments\": enabled_experiments,\n",
        "#                 \"loss_functions\": list(loss_functions.keys()),\n",
        "#                 \"models\": list(model_checkpoints.keys())\n",
        "#             }\n",
        "#         )\n",
        "\n",
        "#         # Analyze and log dataset characteristics\n",
        "#         logger.info(\"Analyzing dataset characteristics...\")\n",
        "#         dataset_stats = analyze_text_lengths(dataset)\n",
        "#         wandb.log({\"dataset_stats\": dataset_stats})\n",
        "\n",
        "#         total_experiments = len([exp for exp in experiment_config.values() if exp[\"enabled\"]])\n",
        "#         completed_experiments = 0\n",
        "\n",
        "#         # Run enabled experiments\n",
        "#         for exp_name, exp_config in experiment_config.items():\n",
        "#             if not exp_config[\"enabled\"]:\n",
        "#                 logger.info(f\"Skipping {exp_config['name']} (disabled)\")\n",
        "#                 continue\n",
        "\n",
        "#             try:\n",
        "#                 logger.info(f\"\\nStarting {exp_config['name']} experiments...\")\n",
        "#                 start_time = time.time()\n",
        "\n",
        "#                 if exp_name == \"bitfit\":\n",
        "#                     # Special handling for BitFit variants\n",
        "#                     for variant in exp_config[\"variants\"]:\n",
        "#                         logger.info(f\"\\nRunning {variant}...\")\n",
        "#                         exp_config[\"function\"](\n",
        "#                             peft_method=variant,\n",
        "#                             **exp_config[\"args\"]\n",
        "#                         )\n",
        "#                 else:\n",
        "#                     # Run standard experiment\n",
        "#                     exp_config[\"function\"](**exp_config[\"args\"])\n",
        "\n",
        "#                 # Log experiment completion time\n",
        "#                 duration = time.time() - start_time\n",
        "#                 logger.info(f\"Completed {exp_config['name']} in {duration:.2f} seconds\")\n",
        "#                 wandb.log({f\"{exp_config['name']}_duration\": duration})\n",
        "\n",
        "#                 completed_experiments += 1\n",
        "#                 logger.info(f\"Progress: {completed_experiments}/{total_experiments} experiments completed\")\n",
        "\n",
        "#             except Exception as exp_error:\n",
        "#                 logger.error(f\"Error in {exp_config['name']}: {str(exp_error)}\")\n",
        "#                 wandb.log({f\"{exp_config['name']}_error\": str(exp_error)})\n",
        "#                 continue\n",
        "\n",
        "#             finally:\n",
        "#                 # Cleanup after each experiment\n",
        "#                 cleanup()\n",
        "\n",
        "#         # Run inference if specified\n",
        "#         if results_dir:\n",
        "#             pass  # Commented out inference for now\n",
        "#             # logger.info(\"\\nRunning inference on best models...\")\n",
        "#             # inference_results = run_inference_and_save_results(\n",
        "#             #     model_checkpoints=model_checkpoints,\n",
        "#             #     test_df=test_df,\n",
        "#             #     results_dir=results_dir\n",
        "#             # )\n",
        "#             # wandb.log({\"inference_results\": inference_results})\n",
        "\n",
        "#     except Exception as e:\n",
        "#         logger.error(f\"Critical error in experiment execution: {str(e)}\")\n",
        "#         wandb.log({\"critical_error\": str(e)})\n",
        "#         raise\n",
        "\n",
        "#     finally:\n",
        "#         # Cleanup and finalize\n",
        "#         cleanup()\n",
        "\n",
        "#         # Log final status to wandb\n",
        "#         if wandb.run is not None:\n",
        "#             wandb.log({\n",
        "#                 \"completed_experiments\": completed_experiments,\n",
        "#                 \"total_experiments\": total_experiments,\n",
        "#                 \"completion_rate\": completed_experiments / total_experiments if total_experiments > 0 else 0\n",
        "#             })\n",
        "#             wandb.finish()\n",
        "\n",
        "#         logger.info(\"\\nExperiment suite completed!\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Import required modules\n",
        "#     import logging\n",
        "#     import time\n",
        "#     import sys\n",
        "#     import torch\n",
        "#     import wandb\n",
        "#     from pathlib import Path\n",
        "\n",
        "#     try:\n",
        "#         # Set up wandb authentication\n",
        "#         authenticate_wandb()\n",
        "\n",
        "#         # Run main function\n",
        "#         main()\n",
        "#     except KeyboardInterrupt:\n",
        "#         logging.getLogger(\"greenland_experiments\").info(\"Experiment interrupted by user\")\n",
        "#         cleanup()\n",
        "#         sys.exit(0)\n",
        "#     except Exception as e:\n",
        "#         logging.getLogger(\"greenland_experiments\").error(f\"Unhandled exception: {str(e)}\")\n",
        "#         cleanup()\n",
        "#         raise"
      ],
      "metadata": {
        "id": "lec6PHkIkXdH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linguistic Configuration"
      ],
      "metadata": {
        "id": "BBvM7FohkLnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training configurations\n",
        "LINGUISTIC_RELATIONS = {\n",
        "    \"genetic\": {\n",
        "        \"description\": \"Language relationships based on genetic/family groupings\",\n",
        "        \"objectives\": {\n",
        "            \"head_to_tail\": \"Cross-lingual transfer from high-resource to low-resource languages\",\n",
        "            \"head_and_tail\": \"Multilingual training with both high and low resource languages\",\n",
        "            \"tail_to_tail\": \"Low-resource transfer between similar low-resource languages\"\n",
        "        }\n",
        "    },\n",
        "    \"script\": {\n",
        "        \"description\": \"Language relationships based on writing systems\",\n",
        "        \"objectives\": {\n",
        "            \"head_to_tail\": \"Cross-lingual transfer from high-resource to low-resource languages\",\n",
        "            \"head_and_tail\": \"Multilingual training with both high and low resource languages\",\n",
        "            \"tail_to_tail\": \"Low-resource transfer between similar low-resource languages\"\n",
        "        }\n",
        "    },\n",
        "    \"word_order\": {\n",
        "        \"description\": \"Language relationships based on syntactic structure\",\n",
        "        \"objectives\": {\n",
        "            \"head_to_tail\": \"Cross-lingual transfer from high-resource to low-resource languages\",\n",
        "            \"head_and_tail\": \"Multilingual training with both high and low resource languages\",\n",
        "            \"tail_to_tail\": \"Low-resource transfer between similar low-resource languages\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "def load_linguistic_datasets(relation_type, objective, sample_size=1000):\n",
        "    \"\"\"\n",
        "    Load datasets for a specific linguistic relation and training objective\n",
        "\n",
        "    Args:\n",
        "        relation_type (str): One of 'genetic', 'script', or 'word_order'\n",
        "        objective (str): One of 'head_to_tail', 'head_and_tail', or 'tail_to_tail'\n",
        "        sample_size (int): Number of samples to use (for testing, set to None for full dataset)\n",
        "    \"\"\"\n",
        "    base_path = f'/content/drive/MyDrive/GREENLAND/Datasets/Consolidated_Data/Experiment_Training_Splits/{relation_type}/{objective}'\n",
        "\n",
        "    try:\n",
        "        train_df = pd.read_csv(f'{base_path}/train.csv')\n",
        "        val_df = pd.read_csv(f'{base_path}/valid.csv')\n",
        "        test_df = pd.read_csv(f'{base_path}/test.csv')\n",
        "\n",
        "        logger.info(f\"Successfully loaded data from {base_path}\")\n",
        "        logger.info(f\"Original sizes - Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
        "\n",
        "        # Sample data if sample_size is provided\n",
        "        if sample_size:\n",
        "            train_df = train_df.sample(n=min(sample_size, len(train_df)), random_state=42)\n",
        "            val_df = val_df.sample(n=min(sample_size, len(val_df)), random_state=42)\n",
        "            test_df = test_df.sample(n=min(sample_size, len(test_df)), random_state=42)\n",
        "            logger.info(f\"Sampled sizes - Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
        "\n",
        "        # Convert to HuggingFace datasets\n",
        "        train_dataset = Dataset.from_pandas(train_df)\n",
        "        val_dataset = Dataset.from_pandas(val_df)\n",
        "        test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "        return {\n",
        "            \"train\": train_dataset,\n",
        "            \"validation\": val_dataset,\n",
        "            \"test\": test_dataset\n",
        "        }\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        logger.error(f\"Could not find data files in {base_path}: {str(e)}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading datasets: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def get_save_paths(relation_type, objective, model_name=None):\n",
        "    \"\"\"\n",
        "    Generate save paths for a specific configuration\n",
        "\n",
        "    Args:\n",
        "        relation_type (str): Linguistic relationship type\n",
        "        objective (str): Training objective\n",
        "        model_name (str, optional): Model name for specific model saves\n",
        "    \"\"\"\n",
        "    base_name = f\"{relation_type}_{objective}\"\n",
        "    if model_name:\n",
        "        base_name = f\"{base_name}_{model_name}\"\n",
        "\n",
        "    paths = {\n",
        "        \"local\": os.path.join(local_save_path, base_name),\n",
        "        \"drive\": os.path.join(drive_save_path, base_name),\n",
        "        \"results\": os.path.join(results_dir, base_name)\n",
        "    }\n",
        "\n",
        "    # Create directories if they don't exist\n",
        "    for path in paths.values():\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    return paths\n",
        "\n",
        "def train_linguistic_configuration(relation_type, objective, model_checkpoints, training_method=\"adapter\"):\n",
        "    \"\"\"\n",
        "    Train models for a specific linguistic relation and objective\n",
        "\n",
        "    Args:\n",
        "        relation_type (str): Linguistic relationship type\n",
        "        objective (str): Training objective\n",
        "        model_checkpoints (dict): Model configurations\n",
        "        training_method (str): One of 'adapter', 'full_ft', 'peft', 'bitfit'\n",
        "    \"\"\"\n",
        "    # Initialize configuration name\n",
        "    config_name = f\"{relation_type}_{objective}_{training_method}\"\n",
        "    logger.info(f\"\\nStarting training for configuration: {config_name}\")\n",
        "\n",
        "    try:\n",
        "        dataset = load_linguistic_datasets(relation_type, objective)\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        loss_functions = get_loss_functions(device)\n",
        "\n",
        "        wandb.init(\n",
        "            project=\"greenland\",\n",
        "            name=config_name,\n",
        "            config={\n",
        "                \"relation_type\": relation_type,\n",
        "                \"objective\": objective,\n",
        "                \"training_method\": training_method,\n",
        "                \"models\": list(model_checkpoints.keys()),\n",
        "                \"device\": str(device)\n",
        "            }\n",
        "        )\n",
        "\n",
        "        if training_method == \"adapter\":\n",
        "            adapter_fine_tune_all_models(\n",
        "                model_checkpoints=model_checkpoints,\n",
        "                dataset=dataset,\n",
        "                loss_functions=loss_functions,\n",
        "                relation_type=relation_type,\n",
        "                objective=objective\n",
        "            )\n",
        "        elif training_method == \"full_ft\":\n",
        "            full_fine_tune_all_models(\n",
        "                model_checkpoints=model_checkpoints,\n",
        "                dataset=dataset,\n",
        "                loss_functions=loss_functions,\n",
        "                relation_type=relation_type,\n",
        "                objective=objective\n",
        "            )\n",
        "        elif training_method == \"peft\":\n",
        "            peft_fine_tune_all_models(\n",
        "                model_checkpoints=model_checkpoints,\n",
        "                dataset=dataset,\n",
        "                loss_functions=loss_functions,\n",
        "                relation_type=relation_type,\n",
        "                objective=objective\n",
        "            )\n",
        "        elif training_method == \"bitfit\":\n",
        "            for bitfit_variant in [\"BitFit Full Fine-Tuning\", \"U-BitFit\", \"S-BitFit\"]:\n",
        "                bitfit_peft_fine_tune_all_models(\n",
        "                    model_checkpoints=model_checkpoints,\n",
        "                    dataset=dataset,\n",
        "                    loss_functions=loss_functions,\n",
        "                    peft_method=bitfit_variant,\n",
        "                    k=100,\n",
        "                    relation_type=relation_type,\n",
        "                    objective=objective\n",
        "                )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in configuration {config_name}: {str(e)}\")\n",
        "        raise\n",
        "    finally:\n",
        "        wandb.finish()\n",
        "        cleanup()\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function for all configurations\"\"\"\n",
        "    # Define configurations\n",
        "    configurations = {\n",
        "        \"genetic\": [\"head_to_tail\", \"head_and_tail\", \"tail_to_tail\"],\n",
        "        \"script\": [\"head_to_tail\", \"head_and_tail\", \"tail_to_tail\"],\n",
        "        \"word_order\": [\"head_to_tail\", \"head_and_tail\", \"tail_to_tail\"]\n",
        "    }\n",
        "\n",
        "    # Define training methods\n",
        "    training_methods = [\"full_ft\"]  # Add other methods as needed\n",
        "\n",
        "    # Initialize wandb\n",
        "    authenticate_wandb()\n",
        "\n",
        "    total_configs = len(configurations) * len(training_methods) * 3  # 3 objectives per relation\n",
        "    completed_configs = 0\n",
        "\n",
        "    try:\n",
        "        for relation_type, objectives in configurations.items():\n",
        "            for objective in objectives:\n",
        "                for method in training_methods:\n",
        "                    try:\n",
        "                        logger.info(f\"\\nStarting configuration {completed_configs + 1}/{total_configs}\")\n",
        "                        logger.info(f\"Relation: {relation_type}, Objective: {objective}, Method: {method}\")\n",
        "\n",
        "                        train_linguistic_configuration(\n",
        "                            relation_type=relation_type,\n",
        "                            objective=objective,\n",
        "                            model_checkpoints=model_checkpoints,\n",
        "                            training_method=method\n",
        "                        )\n",
        "\n",
        "                        completed_configs += 1\n",
        "                        logger.info(f\"Completed {completed_configs}/{total_configs} configurations\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error in configuration - Relation: {relation_type}, \"\n",
        "                                   f\"Objective: {objective}, Method: {method}\")\n",
        "                        logger.error(str(e))\n",
        "                        continue\n",
        "\n",
        "                    finally:\n",
        "                        cleanup()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        logger.info(\"\\nExperiment interrupted by user\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Unhandled exception in main execution: {str(e)}\")\n",
        "    finally:\n",
        "        logger.info(f\"\\nExperiment completed. Successful configurations: {completed_configs}/{total_configs}\")\n",
        "        cleanup()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "1uKUYrDTuwLu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5ed94b9e45574e7ebca224017982b160",
            "2107f762b3834ae19a5186e391d756fd",
            "215542cd266341d6965b108d9e614bac",
            "8f2986b5cd2a4e589df8d629061ce145",
            "88fa9a471afc4b6dad2c7f91df4e77cf",
            "f747e21eccc3491a93de097510e1e65b",
            "c726d36ffb5b4d7fbe87dff23164056a",
            "eadf73fea5ef474e9d9ca582fa2d6b96",
            "dd8dd0195df24337bc7901ca74175507",
            "acb2d86572fe430aa648c844641f90d0",
            "4907b2fb7ae44728a7bcd0a7042a5738",
            "2510e5d667174a67bf0b93766eaa75f5",
            "d230936a23df4735b2ef714a6a185d0d",
            "a6f68e15e20d47e2a10d173fde9fe943",
            "c92129b430fa490aad143828abd01776",
            "02be3322d78a4943bd034af8fd1f46d0",
            "7b7af6b8ecb14416a1b83dfed8c4b763",
            "99817e8a8db245dfb35b61e8010242a1",
            "27d42958b5f44dd5bb386f3b0c19835f",
            "e2bcb885a72d4b8b8ea90b5f1144da52",
            "0402c1afe7a2446e81f6c51aff81f995",
            "522137992ce84613a3804d8878c91111",
            "92469b57a7bc43b4893717c2b6d5c0ca",
            "7b04324f857d45e585f9efb81af1db7c",
            "758aadcb92254f55bc6f0df294a94595",
            "21d95ce755e34890916f87836d5e6eaf",
            "15049c4ca78b4c20af32d79f55f58405",
            "624024b6cf154446a4442d506c39d627",
            "b81dd732b5574fad98d46a21763b4ea9",
            "075f48b830264b12bfab8be4911635cf",
            "cd920bcfb590461787227f5c3451525f",
            "fd10842ad9a64ffb988b5e2304e7af2f",
            "c04d935ac0bb4255a6e513ca319620bc",
            "47f2b353eee24414b28070c57a36541d",
            "36175dd818c5475c877ce4fcf6a75078",
            "f164ef958b084d25acf9c1ad852bcb31",
            "eba9c5a353084b13bdf45f00967800b9",
            "3171d68c40694cb2b5ec2efc45f32536",
            "7ec14253bc6d40b3906e2ee0d4685ec5",
            "001d70cd5ff447c3ba34e26f0a90b672",
            "784a37e9865c4acba1f32aec242ce4ff",
            "e4c52322092b4de5a3c8ca59c4aed696",
            "890e4488222f4a049aa6b3a993a83c4f",
            "f3381036e4b240609055bce25e492354",
            "a0b492f70be9414690ea0d4f4203d701",
            "5466e5162bf24028970e801c861a7c34",
            "3c1771a68d6d457195f358739cc69826",
            "6dd5978f95844c15a33b901c57dcfb12",
            "c703236c8aa14bd4afa07898020efa67",
            "9c197206d4334717bfd5da0872636173",
            "f025a0a98ed543bbb9acf36a4254073c",
            "c1c23cc3be1048a490eca2300d6ea475",
            "4bbe5ff555684b4a8ac01333d3a8847e",
            "7712e13e637a49dba92a4cb37556d664",
            "512acf5d67ba4394b6b5f0bd2d6759e1",
            "baf443f1024d4cb880b374cc6636c124",
            "9e9d9b2616194a70910189c7a0cd1099",
            "7bab4512815644deb070e008f2f2b4a3",
            "59e7f4bb34b14669b8a8c9f663b0b352",
            "ce1204e7718f47bb8e44f611fa179f29",
            "826c7237515c4954a273c5d5e08bad8b",
            "808e44af5e8d40239dab6ff4427b570d",
            "e9c780d21a724869b67794579b389bc0",
            "58f0ccefa8564b949e8b256a7291d64e",
            "5300ad3406674ac39837e2144a0ff50f",
            "445a01957cd64a24833c7899fcdff506",
            "b52a58a93aa8497f8720cc5865f265db",
            "aedced192db64b909e5998b7171b70b4",
            "49144f22d3bb4db29dd076a19a278394",
            "840d2f77382d4e18baff50780084bd05",
            "d55ec2aa46394d85bb7bb6f16ee5bf0a",
            "cf633764cd6746949e610eeebccdfd41",
            "b5842924f3ae4910bb5b725dee913dd6",
            "9018d8d77d0e45fdac3d0cb704dcd955",
            "c296057c9b0b4d8793dcf3814f31774c",
            "6c118c2389644be1b8d71d38b3fd9486",
            "abf305588c734b57ba9de99b679ef5bf",
            "d03a3c42d0e945be8e93889712aed2cb",
            "c4cff48318954e6e8bdeb0b488ba3843",
            "5d6c502174f94e869d4d98614aed3627",
            "206530d7fa144410b945571fb0cf18b8",
            "1939141bb3eb4467a27d5604b305eb3f",
            "023492ec7e524aab84ff3a047e048c7c",
            "a4155944373945a388c47e27e29210ba",
            "128ac639c0dd47e6b525a8771ee29620",
            "2a1d4bfb04ad4134bd9064f3b8f80ccb",
            "284a0ae2655e48138b501482fa2ceea0",
            "598a4e11da4745349d049ac576784366",
            "2473c99a80ed480986d2e3c1cbf7f3c4",
            "cd002dc153ba4cc999197a12eab99638",
            "b54b5e13e24e4d6e8e5723b70c13f296",
            "f2911d49431245ecb73824f1f828233b",
            "f9adc1192538480a9b6c053bdb5f0dbd",
            "39bd9830f06e4c97ad41e62cf2bc48e4",
            "02e3cf1a3d7149eaa5a7e8326103a9d9",
            "3c3ffead59374fa69671023ce4f247b3",
            "71b5f88b9efa49f782bd03801f81b083",
            "5c46d7268e6448b8a84c705fba972322",
            "e33a3162627b49b9b9df49401db15662",
            "cb444ef48f3e4980b7ce2e0d243c2216",
            "03e73a9b8a4b4c7db1c814efd5bc9d6d",
            "c8fe6511225c4077b48092d92a55c43d",
            "220804f0ce294807a32e6899fa7ef325",
            "835f8010a49c4f13bba2a58bc0c970ec",
            "57989d7da060423f91b2a8498b90d1a0",
            "218f7b8e3c1943f2ba7adee2e7a99c84",
            "be30dfd2d581439f80d3effdc1281bfe",
            "4d3ec6ea6f6a445ab5a3dc0ff0f467e0",
            "578c0bb0f6d34b47b4ec459ac6ca07b2",
            "f070f768b4d64855a3420cf7933d3a6c",
            "a8d04b87ecaf4034a7fdb0625e038331",
            "e18c513402b9417ebeb52a3e970ef672",
            "40bd9e818807482a97200779e4761c6b",
            "b135de22c608472d9b4be4563e10651c",
            "77bfa1f6a91c4a50a645f4d704a51a79"
          ]
        },
        "outputId": "dbf8e332-3877-4751-f271-ae2c75f08cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241129_074445-8mtgffi6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pike/greenland/runs/8mtgffi6' target=\"_blank\">ruby-shape-372</a></strong> to <a href='https://wandb.ai/pike/greenland' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/pike/greenland' target=\"_blank\">https://wandb.ai/pike/greenland</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/pike/greenland/runs/8mtgffi6' target=\"_blank\">https://wandb.ai/pike/greenland/runs/8mtgffi6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authentication successful!\n",
            "\u001b[32m2024-11-29 07:44:47,072 - greenland_experiments - INFO - \n",
            "Starting configuration 1/9\u001b[0m\n",
            "\u001b[32m2024-11-29 07:44:47,072 - greenland_experiments - INFO - \n",
            "Starting configuration 1/9\u001b[0m\n",
            "\u001b[32m2024-11-29 07:44:47,076 - greenland_experiments - INFO - Relation: genetic, Objective: head_to_tail, Method: full_ft\u001b[0m\n",
            "\u001b[32m2024-11-29 07:44:47,076 - greenland_experiments - INFO - Relation: genetic, Objective: head_to_tail, Method: full_ft\u001b[0m\n",
            "\u001b[32m2024-11-29 07:44:47,080 - greenland_experiments - INFO - \n",
            "Starting training for configuration: genetic_head_to_tail_full_ft\u001b[0m\n",
            "\u001b[32m2024-11-29 07:44:47,080 - greenland_experiments - INFO - \n",
            "Starting training for configuration: genetic_head_to_tail_full_ft\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-83e5937c6959>:44: DtypeWarning: Columns (5,10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  test_df = pd.read_csv(f'{base_path}/test.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2024-11-29 07:45:18,409 - greenland_experiments - INFO - Successfully loaded data from /content/drive/MyDrive/GREENLAND/Datasets/Consolidated_Data/Experiment_Training_Splits/genetic/head_to_tail\u001b[0m\n",
            "\u001b[32m2024-11-29 07:45:18,409 - greenland_experiments - INFO - Successfully loaded data from /content/drive/MyDrive/GREENLAND/Datasets/Consolidated_Data/Experiment_Training_Splits/genetic/head_to_tail\u001b[0m\n",
            "\u001b[32m2024-11-29 07:45:18,414 - greenland_experiments - INFO - Original sizes - Train: 386127, Val: 42903, Test: 293969\u001b[0m\n",
            "\u001b[32m2024-11-29 07:45:18,414 - greenland_experiments - INFO - Original sizes - Train: 386127, Val: 42903, Test: 293969\u001b[0m\n",
            "\u001b[32m2024-11-29 07:45:18,627 - greenland_experiments - INFO - Sampled sizes - Train: 1000, Val: 1000, Test: 1000\u001b[0m\n",
            "\u001b[32m2024-11-29 07:45:18,627 - greenland_experiments - INFO - Sampled sizes - Train: 1000, Val: 1000, Test: 1000\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:8mtgffi6) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.014 MB of 0.014 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ed94b9e45574e7ebca224017982b160"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ruby-shape-372</strong> at: <a href='https://wandb.ai/pike/greenland/runs/8mtgffi6' target=\"_blank\">https://wandb.ai/pike/greenland/runs/8mtgffi6</a><br/> View project at: <a href='https://wandb.ai/pike/greenland' target=\"_blank\">https://wandb.ai/pike/greenland</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241129_074445-8mtgffi6/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:8mtgffi6). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241129_074518-c4qnv3t9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pike/greenland/runs/c4qnv3t9' target=\"_blank\">genetic_head_to_tail_full_ft</a></strong> to <a href='https://wandb.ai/pike/greenland' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/pike/greenland' target=\"_blank\">https://wandb.ai/pike/greenland</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/pike/greenland/runs/c4qnv3t9' target=\"_blank\">https://wandb.ai/pike/greenland/runs/c4qnv3t9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using max_length=512 for model MBERT_uncased\n",
            "\n",
            "Before tokenization:\n",
            "Sample of original labels: [True, True, False, True, False]\n",
            "Original label type: <class 'bool'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train set (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd8dd0195df24337bc7901ca74175507"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing validation set (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2bcb885a72d4b8b8ea90b5f1144da52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing test set (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd920bcfb590461787227f5c3451525f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After tokenization:\n",
            "Sample of processed labels: [1, 1, 0, 1, 0]\n",
            "Processed label type: <class 'int'>\n",
            "\n",
            "Training MBERT_uncased with HuberLoss\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [186/186 00:53, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.070252</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>0.806042</td>\n",
              "      <td>0.681307</td>\n",
              "      <td>0.986686</td>\n",
              "      <td>0.511862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.077500</td>\n",
              "      <td>0.051614</td>\n",
              "      <td>0.859000</td>\n",
              "      <td>0.898195</td>\n",
              "      <td>0.877292</td>\n",
              "      <td>0.920118</td>\n",
              "      <td>0.825800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing evaluation...\n",
            "Running compute_metrics...\n",
            "Performing evaluation...\n",
            "Running compute_metrics...\n",
            "Performing evaluation...\n",
            "Running compute_metrics...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "training_args.bin:   0%|          | 0.00/5.30k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4c52322092b4de5a3c8ca59c4aed696"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bbe5ff555684b4a8ac01333d3a8847e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/669M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58f0ccefa8564b949e8b256a7291d64e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2024-11-29 07:47:00,183 - greenland_experiments - INFO - ✅ Full fine-tuned model saved to Hugging Face Hub as jslai/MBERT_uncased_HuberLoss_full_ft_genetic_head_to_tail_20241129-074625\u001b[0m\n",
            "\u001b[32m2024-11-29 07:47:00,183 - greenland_experiments - INFO - ✅ Full fine-tuned model saved to Hugging Face Hub as jslai/MBERT_uncased_HuberLoss_full_ft_genetic_head_to_tail_20241129-074625\u001b[0m\n",
            "\n",
            "Full Fine-Tuning completed!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁██</td></tr><tr><td>eval/f1</td><td>▁██</td></tr><tr><td>eval/loss</td><td>█▁▁</td></tr><tr><td>eval/precision</td><td>▁█▇</td></tr><tr><td>eval/recall</td><td>█▁▃</td></tr><tr><td>eval/roc_auc</td><td>▁██</td></tr><tr><td>eval/runtime</td><td>█▄▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▅█</td></tr><tr><td>eval/steps_per_second</td><td>▁▅█</td></tr><tr><td>train/epoch</td><td>▁▃▅██</td></tr><tr><td>train/global_step</td><td>▁▃▅███</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.859</td></tr><tr><td>eval/f1</td><td>0.89819</td></tr><tr><td>eval/loss</td><td>0.05161</td></tr><tr><td>eval/precision</td><td>0.87729</td></tr><tr><td>eval/recall</td><td>0.92012</td></tr><tr><td>eval/roc_auc</td><td>0.8258</td></tr><tr><td>eval/runtime</td><td>2.3757</td></tr><tr><td>eval/samples_per_second</td><td>420.92</td></tr><tr><td>eval/steps_per_second</td><td>52.615</td></tr><tr><td>total_flos</td><td>783018500751360.0</td></tr><tr><td>train/epoch</td><td>2.976</td></tr><tr><td>train/global_step</td><td>186</td></tr><tr><td>train/grad_norm</td><td>0.77504</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0775</td></tr><tr><td>train_loss</td><td>0.05969</td></tr><tr><td>train_runtime</td><td>54.6257</td></tr><tr><td>train_samples_per_second</td><td>54.919</td></tr><tr><td>train_steps_per_second</td><td>3.405</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">genetic_head_to_tail_full_ft</strong> at: <a href='https://wandb.ai/pike/greenland/runs/c4qnv3t9' target=\"_blank\">https://wandb.ai/pike/greenland/runs/c4qnv3t9</a><br/> View project at: <a href='https://wandb.ai/pike/greenland' target=\"_blank\">https://wandb.ai/pike/greenland</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241129_074518-c4qnv3t9/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2024-11-29 07:47:02,302 - greenland_experiments - INFO - Completed 1/9 configurations\u001b[0m\n",
            "\u001b[32m2024-11-29 07:47:02,302 - greenland_experiments - INFO - Completed 1/9 configurations\u001b[0m\n",
            "\u001b[32m2024-11-29 07:47:02,306 - greenland_experiments - INFO - \n",
            "Starting configuration 2/9\u001b[0m\n",
            "\u001b[32m2024-11-29 07:47:02,306 - greenland_experiments - INFO - \n",
            "Starting configuration 2/9\u001b[0m\n",
            "\u001b[32m2024-11-29 07:47:02,308 - greenland_experiments - INFO - Relation: genetic, Objective: head_and_tail, Method: full_ft\u001b[0m\n",
            "\u001b[32m2024-11-29 07:47:02,308 - greenland_experiments - INFO - Relation: genetic, Objective: head_and_tail, Method: full_ft\u001b[0m\n",
            "\u001b[32m2024-11-29 07:47:02,311 - greenland_experiments - INFO - \n",
            "Starting training for configuration: genetic_head_and_tail_full_ft\u001b[0m\n",
            "\u001b[32m2024-11-29 07:47:02,311 - greenland_experiments - INFO - \n",
            "Starting training for configuration: genetic_head_and_tail_full_ft\u001b[0m\n",
            "\u001b[32m2024-11-29 07:48:00,896 - greenland_experiments - INFO - Successfully loaded data from /content/drive/MyDrive/GREENLAND/Datasets/Consolidated_Data/Experiment_Training_Splits/genetic/head_and_tail\u001b[0m\n",
            "\u001b[32m2024-11-29 07:48:00,896 - greenland_experiments - INFO - Successfully loaded data from /content/drive/MyDrive/GREENLAND/Datasets/Consolidated_Data/Experiment_Training_Splits/genetic/head_and_tail\u001b[0m\n",
            "\u001b[32m2024-11-29 07:48:00,900 - greenland_experiments - INFO - Original sizes - Train: 520559, Val: 57840, Test: 144600\u001b[0m\n",
            "\u001b[32m2024-11-29 07:48:00,900 - greenland_experiments - INFO - Original sizes - Train: 520559, Val: 57840, Test: 144600\u001b[0m\n",
            "\u001b[32m2024-11-29 07:48:01,102 - greenland_experiments - INFO - Sampled sizes - Train: 1000, Val: 1000, Test: 1000\u001b[0m\n",
            "\u001b[32m2024-11-29 07:48:01,102 - greenland_experiments - INFO - Sampled sizes - Train: 1000, Val: 1000, Test: 1000\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241129_074801-hw0u4l9f</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pike/greenland/runs/hw0u4l9f' target=\"_blank\">genetic_head_and_tail_full_ft</a></strong> to <a href='https://wandb.ai/pike/greenland' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/pike/greenland' target=\"_blank\">https://wandb.ai/pike/greenland</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/pike/greenland/runs/hw0u4l9f' target=\"_blank\">https://wandb.ai/pike/greenland/runs/hw0u4l9f</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using max_length=512 for model MBERT_uncased\n",
            "\n",
            "Before tokenization:\n",
            "Sample of original labels: [False, False, True, True, False]\n",
            "Original label type: <class 'bool'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train set (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c296057c9b0b4d8793dcf3814f31774c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing validation set (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a1d4bfb04ad4134bd9064f3b8f80ccb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing test set (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71b5f88b9efa49f782bd03801f81b083"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After tokenization:\n",
            "Sample of processed labels: [0, 0, 1, 1, 0]\n",
            "Processed label type: <class 'int'>\n",
            "\n",
            "Training MBERT_uncased with HuberLoss\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='187' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [186/186 00:42, Epoch 2.98/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.066529</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.850575</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.074400</td>\n",
              "      <td>0.054303</td>\n",
              "      <td>0.852000</td>\n",
              "      <td>0.899183</td>\n",
              "      <td>0.906593</td>\n",
              "      <td>0.891892</td>\n",
              "      <td>0.815177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing evaluation...\n",
            "Running compute_metrics...\n",
            "Performing evaluation...\n",
            "Running compute_metrics...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.023 MB of 0.023 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d3ec6ea6f6a445ab5a3dc0ff0f467e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2024-11-29 07:49:00,578 - greenland_experiments - INFO - \n",
            "Experiment interrupted by user\u001b[0m\n",
            "\u001b[32m2024-11-29 07:49:00,578 - greenland_experiments - INFO - \n",
            "Experiment interrupted by user\u001b[0m\n",
            "\u001b[32m2024-11-29 07:49:00,585 - greenland_experiments - INFO - \n",
            "Experiment completed. Successful configurations: 1/9\u001b[0m\n",
            "\u001b[32m2024-11-29 07:49:00,585 - greenland_experiments - INFO - \n",
            "Experiment completed. Successful configurations: 1/9\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}